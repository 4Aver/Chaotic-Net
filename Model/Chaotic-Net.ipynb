{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T05:28:51.678396Z",
     "iopub.status.busy": "2025-12-09T05:28:51.678162Z",
     "iopub.status.idle": "2025-12-09T05:29:10.752456Z",
     "shell.execute_reply": "2025-12-09T05:29:10.751403Z",
     "shell.execute_reply.started": "2025-12-09T05:28:51.678367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nolds\n",
      "  Downloading nolds-0.6.3-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from nolds) (1.0.0)\n",
      "Requirement already satisfied: numpy<3.0,>1.0 in /opt/conda/lib/python3.10/site-packages (from nolds) (1.26.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nolds) (69.0.3)\n",
      "Downloading nolds-0.6.3-py2.py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nolds\n",
      "Successfully installed nolds-0.6.3\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nolds\n",
    "!pip install einops\n",
    "# !pip install reformer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.641Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nolds import lyap_e\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "data = pd.read_csv(r'/kaggle/input/original-chaotic-data/Power.csv')\n",
    "print(data)\n",
    "\n",
    "\n",
    "# 计算指定的区域的最大Lyapunov指数\n",
    "def calculate_special_Lyapunov(data,list_break_points):\n",
    "    for i in range(1, len(list_break_points)-1):\n",
    "        b_start = list_break_points[i-1]\n",
    "        break_point = list_break_points[i]\n",
    "        b_end = list_break_points[i+1]\n",
    "        sum_L = 0\n",
    "\n",
    "        M = data.shape[1]\n",
    "        sum_g, sum_s = 0, 0\n",
    "        for m in range(M):\n",
    "            object_data = data.iloc[b_start:b_end,m]\n",
    "            N_length = b_end - b_start\n",
    "            break_point_psition = break_point - b_start\n",
    "\n",
    "            left_data = object_data[:break_point_psition]\n",
    "            right_data = object_data[break_point_psition:]\n",
    "\n",
    "            global_LLE = lyap_e(object_data, emb_dim=10, matrix_dim=4)[0]\n",
    "\n",
    "            LLE1 = lyap_e(left_data, emb_dim=10, matrix_dim=4)[0]\n",
    "            LLE2 = lyap_e(right_data, emb_dim=10, matrix_dim=4)[0]\n",
    "            combine_L = (LLE1 * break_point_psition + LLE2 * (N_length-break_point_psition)) / N_length\n",
    "            L = global_LLE - combine_L\n",
    "            sum_g += global_LLE\n",
    "            sum_s += combine_L\n",
    "            print('{}-{}-{}'.format(b_start,break_point,b_end),global_LLE,combine_L,L,'混乱程度降低了：{:.5}%'.format(L*100/global_LLE))\n",
    "        print(sum_g,sum_s,'混乱程度降低了：{:.5}%'.format((sum_g-sum_s)*100/sum_g))\n",
    "# calculate_special_Lyapunov(data,[0, 1500, 4000])\n",
    "\n",
    "\n",
    "def AddNewBreakpoints(object_data, b_start, b_end, M, time_gap = 10, point_gap = 1000):\n",
    "    '''\n",
    "    :param object_data: 需要新添加的分割点的目标数据\n",
    "    :param b_start: 开始的位置点\n",
    "    :param b_end: 结束的位置点\n",
    "    :param time_gap: 时间间隔\n",
    "    :return: 位置点\n",
    "    '''\n",
    "    max_sum_L, find_b = 0, None\n",
    "    object_N = b_end - b_start\n",
    "    b_s, b_e = b_start + point_gap, b_end - point_gap       # 加上长度限制\n",
    "\n",
    "    list_global_LLE = []\n",
    "    for m in range(M):\n",
    "        global_LLE = lyap_e(object_data.iloc[b_start:b_end,m], emb_dim=10, matrix_dim=4)[0]\n",
    "        list_global_LLE.append(global_LLE)\n",
    "\n",
    "    for i in range(b_s, b_e, time_gap):\n",
    "        sum_L = 0\n",
    "        for m in range(M):\n",
    "            object_data_special = object_data.iloc[:,m].tolist()\n",
    "            length = i - b_start      # 获得长度\n",
    "\n",
    "            LLE1 = lyap_e(object_data_special[b_start:i], emb_dim=10, matrix_dim=4)[0]\n",
    "            LLE2 = lyap_e(object_data_special[i:b_end], emb_dim=10, matrix_dim=4)[0]\n",
    "            L = list_global_LLE[m] - (LLE1 * length + LLE2 * (object_N-length)) / object_N\n",
    "            print(list_global_LLE[m],LLE1,LLE2,L)\n",
    "\n",
    "            sum_L += L        # 对多变量的L求和，取大于0的最大值的对应的分割点\n",
    "        if sum_L > max_sum_L:\n",
    "            max_sum_L = sum_L\n",
    "            find_b = i\n",
    "        else:\n",
    "            continue\n",
    "    return find_b\n",
    "\n",
    "\n",
    "# 在多变量中去切分\n",
    "def Multi_Greedy_Lyapunov_Segment(data, point_gap=1000):\n",
    "    N, M = data.shape\n",
    "    break_points = []\n",
    "    start, end = 0, N + 1\n",
    "    current_breaks = [start, end]\n",
    "\n",
    "    while current_breaks:\n",
    "        new_breaks = []\n",
    "        for i in range(len(current_breaks) - 1):\n",
    "            print(current_breaks[i], current_breaks[i+1],data[current_breaks[i]:current_breaks[i+1]].shape,current_breaks)\n",
    "\n",
    "            if current_breaks[i+1] - current_breaks[i] > point_gap*2:\n",
    "                mid = AddNewBreakpoints(data, current_breaks[i], current_breaks[i+1],M, time_gap=50, point_gap=1000)\n",
    "                if mid:\n",
    "                    new_breaks.extend([current_breaks[i], mid, current_breaks[i+1]])\n",
    "                    break_points.append(mid)\n",
    "                else:\n",
    "                    new_breaks.append(current_breaks[i])\n",
    "            else:\n",
    "                new_breaks.append(current_breaks[i])\n",
    "                print('长度不够，没办法进行切分！')\n",
    "\n",
    "        current_breaks = new_breaks\n",
    "    print(break_points)\n",
    "    return break_points\n",
    "Multi_Greedy_Lyapunov_Segment(data.iloc[:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaotic-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 消融实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.643Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wo2_MoEE\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "    q = q.contiguous()\n",
    "    k = k.contiguous()\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, out_channels=10, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "\n",
    "        self.list_input_dim = list_input_dim\n",
    "        self.list_conv = nn.ModuleList()\n",
    "        for input_dim in list_input_dim:\n",
    "            # 定义PwConv将不同的嵌入维数映射到相同的嵌入维数，并没有提取时间信息，某方面说提取到了特征之间的信息\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                          stride=emb_stride),\n",
    "                nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=1)\n",
    "                )\n",
    "            self.list_conv.append(conv_layer)\n",
    "        self.inst_norm = nn.InstanceNorm1d(out_channels)  # 实例化归一化层\n",
    "\n",
    "    def forward(self, x):\n",
    "        index = 0\n",
    "        combine_features = torch.Tensor(0).to(device)\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            index += dim\n",
    "            out = self.list_conv[i](input_x).to(device)\n",
    "\n",
    "            combine_features = torch.cat((combine_features, out.unsqueeze(1)), dim=1)\n",
    "        return combine_features\n",
    "\n",
    " \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, seq_len, dropout=0.1, gate_mlp=False):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((seq_len, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gate_mlp = gate_mlp\n",
    "        self.gate_linear = nn.Linear(d_in, d_hid)\n",
    "        self.silu = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        if self.gate_mlp == False:\n",
    "            x = self.w_2(F.relu(self.w_1(x)))\n",
    "\n",
    "        else:\n",
    "            x = self.w_2(F.relu(self.w_1(x) * (self.silu(self.gate_linear(x)))))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, seq_len, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_hiddens = num_hiddens\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, num_hiddens, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=num_hiddens // num_heads, seq_len=seq_len)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d), dim=-1)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "\n",
    "class wo2_MoEE_Model(nn.Module):\n",
    "    def __init__(self, M, time_len, list_input_dims, d=64, num_layers=1):\n",
    "        super(wo2_MoEE_Model, self).__init__()\n",
    "        self.M = M\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "\n",
    "        # self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d, num_experts=num_experts, k=k)\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d)\n",
    "\n",
    "        time_lens= 30\n",
    "        self.indenpendet_transformer = nn.ModuleList([MultiAttention(input_dim=d, num_hiddens=d, num_heads=8,seq_len=time_lens).to(device) for _ in range(M)])\n",
    "        self.list_ln = nn.ModuleList([nn.LayerNorm(normalized_shape=(time_lens, d)) for _ in range(M)])\n",
    "        self.indenpendet_FFN = nn.ModuleList([PositionwiseFeedForward(d, d, seq_len=time_lens,gate_mlp=True).to(device) for _ in range(M)])\n",
    "\n",
    "        # self.dagcn = Mulit_DAGCN(num_time_steps=30, num_nodes=M, in_dims=d, out_dims=d, cheb_k=3, embed_dim=2)\n",
    "        self.dagcn = Attention_DAGCN(num_time_steps=time_lens, num_nodes=M, embed_dim=5, in_dims=d,out_dims=d)\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=(time_lens, d))\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(1) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d, seq_len=time_lens)\n",
    "        self.FFN2 = PositionwiseFeedForward(d, d, seq_len=time_lens)\n",
    "\n",
    "        self.linear_time = nn.Linear(time_lens, 1)\n",
    "        self.linear_feat = nn.Linear(M * d, 1)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "\n",
    "        for _ in range(self.num_layers):       \n",
    "            list_independent_x = []\n",
    "            for i in range(self.M):\n",
    "                in_x = x[:, i, :, :]\n",
    "\n",
    "                independent_x = self.indenpendet_transformer[i](in_x)\n",
    "                independent_x = self.list_ln[i](in_x + independent_x)\n",
    "                independent_x = self.indenpendet_FFN[i](independent_x) + in_x\n",
    "                list_independent_x.append(independent_x.unsqueeze(1))\n",
    "            \n",
    "            independent_x = torch.cat(list_independent_x, dim=1)\n",
    "            # independent_x = self.dagcn(independent_x.permute(0, 2, 1, 3)).permute(0, 2, 1, 3)\n",
    "            \n",
    "            dagcn_x, scores, supports = self.dagcn(independent_x + x)\n",
    "            x = self.FFN2(self.ln2(dagcn_x))+ x\n",
    "            # x = self.FFN2(dagcn_x)+ x\n",
    "            # x = independent_x + x\n",
    "\n",
    "        out = self.linear_time(x.transpose(2, 3)).squeeze(-1)\n",
    "        out = self.linear_feat(out.reshape(B, -1))\n",
    "        return out, _, _, _, _\n",
    "\n",
    "    def print_concat_weights(self):\n",
    "        print('Independent Transformer and DAGCN concat weights:', self.dn_embeddings)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # B,L,D\n",
    "#     model = wo2_MoEE_Model(time_len=32,M=3,list_input_dims=[5,5,5])\n",
    "#     out, _, _, _, _ = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.644Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wo3_independent\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, num_experts=8, out_channels=10, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "        self.k = 2\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "        self.list_input_dim = list_input_dim\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        for input_dim in list_input_dim:\n",
    "            experts = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                          stride=emb_stride),\n",
    "                nn.Tanh(),\n",
    "                nn.Conv1d(in_channels=out_channels, out_channels=out_channels * num_experts, kernel_size=1))\n",
    "\n",
    "            # gating = nn.Linear(input_dim, num_experts)\n",
    "            # noise = nn.Linear(input_dim,num_experts)\n",
    "\n",
    "            w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "            self.list_m_experts.append(experts)\n",
    "            self.list_m_gating.append(w_gate)\n",
    "            self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, m, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[m]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[m]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_combine_features = []\n",
    "        list_spatial_x = []\n",
    "        list_gates = []\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            list_spatial_x.append(x[:, index, :].unsqueeze(1))\n",
    "            index += dim\n",
    "\n",
    "            B, d, L = input_x.shape\n",
    "            # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "            gates, load = self.noisy_top_k_gating(input_x[:, :, -6:-1].reshape(B, dim * 5), i, self.training)\n",
    "            list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "            # calculate importance loss\n",
    "            importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "            loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "            loss *= loss_coef\n",
    "            out_loss = out_loss + loss\n",
    "\n",
    "            out_raw = self.list_m_experts[i](input_x)  # B,D*E,l\n",
    "            out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "            moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "            list_combine_features.append(moe_out.unsqueeze(1))\n",
    "        combine_features = torch.cat(list_combine_features, dim=1)\n",
    "        gates = torch.cat(list_gates, dim=-1)\n",
    "        return combine_features, out_loss, gates\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((30, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.w_2(F.relu(self.w_1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, input_dim, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=input_dim // num_heads, seq_len=30)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, input_dim // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, input_dim // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d),dim=-1)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "\n",
    "class wo3_independent_Model(nn.Module):\n",
    "    def __init__(self, M, time_len, list_input_dims, d=64, num_layers=1):\n",
    "        super(wo3_independent_Model, self).__init__()\n",
    "        self.M = M\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d)\n",
    "        self.ln = nn.LayerNorm(normalized_shape=(30, d))\n",
    "\n",
    "        self.mix_transformer = MultiAttention(input_dim=d, num_hiddens=d, num_heads=8)\n",
    "        self.mix_FFN = PositionwiseFeedForward(d, d)\n",
    "\n",
    "        # self.dagcn = Mulit_DAGCN(num_time_steps=30, num_nodes=M, in_dims=d, out_dims=d, cheb_k=3, embed_dim=2)\n",
    "        self.dagcn = Attention_DAGCN(num_time_steps=30, num_nodes=M, embed_dim=3, in_dims=d,out_dims=d)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(2) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d)\n",
    "\n",
    "        self.linear_time = nn.Linear(30, 1)\n",
    "        self.linear_feat = nn.Linear(M * d, 1)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x, loss, gates = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            x = x.reshape(-1,x.shape[2],x.shape[3])\n",
    "            mix_x = self.mix_transformer(x)\n",
    "            mix_x = self.ln(x + mix_x)\n",
    "            mix_x = self.mix_FFN(mix_x)\n",
    "            x = mix_x.reshape(B,-1,x.shape[1],x.shape[2])\n",
    "\n",
    "            mix_x,_,_ = self.dagcn(x)\n",
    "            x = self.FFN(self.ln(mix_x + x))\n",
    "\n",
    "        out = self.linear_time(x.transpose(2, 3)).squeeze(-1)\n",
    "        out = self.linear_feat(out.reshape(B, -1))\n",
    "        return out, loss, gates, _, _\n",
    "\n",
    "    def print_concat_weights(self):\n",
    "        print('Independent Transformer and DAGCN concat weights:', self.dn_embeddings)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # B,L,D\n",
    "#     model = wo3_independent_Model(time_len=32,M=3,list_input_dims=[5,5,5])\n",
    "#     out, _, gates = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.644Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wo4_Transformer\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        其实这就是一个裁剪的模块，裁剪多出来的padding\n",
    "        \"\"\"\n",
    "        # print(x,x.shape)\n",
    "        # print(x[:, :, :-self.chomp_size].contiguous(),x[:, :, :-self.chomp_size].contiguous().shape)\n",
    "        # print('以进行裁剪')\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        \"\"\"\n",
    "        相当于一个Residual block\n",
    "\n",
    "        :param n_inputs: int, 输入通道数\n",
    "        :param n_outputs: int, 输出通道数\n",
    "        :param kernel_size: int, 卷积核尺寸\n",
    "        :param stride: int, 步长，一般为1\n",
    "        :param dilation: int, 膨胀系数\n",
    "        :param padding: int, 填充系数\n",
    "        :param dropout: float, dropout比率\n",
    "        \"\"\"\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        # 经过conv1，输出的size其实是(Batch, input_channel, seq_len + padding)\n",
    "        self.chomp1 = Chomp1d(padding)  # 裁剪掉多出来的padding部分，维持输出时间步为seq_len\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)  # 裁剪掉多出来的padding部分，维持输出时间步为seq_len\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        参数初始化\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # print(self.conv1.weight.shape)\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs,seq_len, num_channels,pred_len, kernel_size=2, dropout=0.2):\n",
    "        \"\"\"\n",
    "        TCN，目前paper给出的TCN结构很好的支持每个时刻为一个数的情况，即sequence结构，\n",
    "        对于每个时刻为一个向量这种一维结构，勉强可以把向量拆成若干该时刻的输入通道，\n",
    "        对于每个时刻为一个矩阵或更高维图像的情况，就不太好办。\n",
    "\n",
    "        :param num_inputs: int， 输入通道数\n",
    "        :param num_channels: list，每层的hidden_channel数，例如[25,25,25,25]表示有4个隐层，每层hidden_channel数为25，也就代表有25个卷积核在这次卷积中执行\n",
    "        :param kernel_size: int, 卷积核尺寸，只需要定义卷积核长度\n",
    "        :param dropout: float, drop_out比率\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i  # 膨胀系数：1，2，4，8……\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i - 1]  # 确定每一层的输入通道数\n",
    "            out_channels = num_channels[i]  # 确定每一层的输出通道数\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n",
    "                                     dilation=dilation_size,                        # 膨胀卷积\n",
    "                                     padding=(kernel_size - 1) * dilation_size,     # 因果卷积\n",
    "                                     dropout=dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.dense_pred = nn.Linear(seq_len,pred_len)\n",
    "        self.dense_feature = nn.Linear(num_channels[-1],1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入x的结构不同于RNN，一般RNN的size为(Batch, seq_len, channels)或者(seq_len, Batch, channels)，\n",
    "        这里把seq_len放在channels后面，把所有时间步的数据拼起来，当做Conv1d的输入尺寸，实现卷积跨时间步的操作，\n",
    "        很巧妙的设计。\n",
    "\n",
    "        为什么输入和输出数据结构是这样的\n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return: size of (Batch, output_channel, seq_len)\n",
    "        \"\"\"\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.network(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, num_experts=8, out_channels=10, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "        self.k = 2\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "        self.list_input_dim = list_input_dim\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        for input_dim in list_input_dim:\n",
    "            experts = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                          stride=emb_stride),\n",
    "                nn.Tanh(),\n",
    "                nn.Conv1d(in_channels=out_channels, out_channels=out_channels * num_experts, kernel_size=1))\n",
    "\n",
    "            # gating = nn.Linear(input_dim, num_experts)\n",
    "            # noise = nn.Linear(input_dim,num_experts)\n",
    "\n",
    "            w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "            self.list_m_experts.append(experts)\n",
    "            self.list_m_gating.append(w_gate)\n",
    "            self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, m, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[m]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[m]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_combine_features = []\n",
    "        list_spatial_x = []\n",
    "        list_gates = []\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            list_spatial_x.append(x[:, index, :].unsqueeze(1))\n",
    "            index += dim\n",
    "\n",
    "            B, d, L = input_x.shape\n",
    "            # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "            gates, load = self.noisy_top_k_gating(input_x[:, :, -6:-1].reshape(B, dim * 5), i, self.training)\n",
    "            list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "            # calculate importance loss\n",
    "            importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "            loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "            loss *= loss_coef\n",
    "            out_loss = out_loss + loss\n",
    "\n",
    "            out_raw = self.list_m_experts[i](input_x)  # B,D*E,l\n",
    "            out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "            moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "            list_combine_features.append(moe_out.unsqueeze(1))\n",
    "        combine_features = torch.cat(list_combine_features, dim=1)\n",
    "        gates = torch.cat(list_gates, dim=-1)\n",
    "        return combine_features, out_loss, gates\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((30, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.w_2(F.relu(self.w_1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, input_dim, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=input_dim // num_heads, seq_len=30)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, input_dim // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, input_dim // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d),dim=-1)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "\n",
    "class wo4_Transformer_Model(nn.Module):\n",
    "    def __init__(self, M, time_len, list_input_dims,type_model='MLP', d=64, num_layers=1):\n",
    "        super(wo4_Transformer_Model, self).__init__()\n",
    "        self.M = M\n",
    "        self.type_model = type_model\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d)\n",
    "        self.ln = nn.LayerNorm(normalized_shape=(30, d))\n",
    "        self.list_ln = nn.ModuleList([nn.LayerNorm(normalized_shape=(30, d)) for _ in range(M)])\n",
    "\n",
    "        if type_model == 'MLP':\n",
    "            self.indenpendet_layer = nn.ModuleList([PositionwiseFeedForward(d, d).to(device) for _ in range(M)])\n",
    "\n",
    "        if type_model == 'LSTM':\n",
    "            layer = nn.Sequential(nn.LSTM(d, d, batch_first=True))\n",
    "            self.indenpendet_layer = nn.ModuleList([layer.to(device) for _ in range(M)])\n",
    "\n",
    "        if type_model == 'TCN':\n",
    "            layer = nn.Sequential(TemporalConvNet(num_inputs=d, num_channels=[d], kernel_size=2,seq_len=time_len,pred_len=1))\n",
    "            self.indenpendet_layer = nn.ModuleList([layer.to(device) for _ in range(M)])\n",
    "\n",
    "        # self.dagcn = Mulit_DAGCN(num_time_steps=30, num_nodes=M, in_dims=d, out_dims=d, cheb_k=3, embed_dim=2)\n",
    "        self.dagcn = Attention_DAGCN(num_time_steps=30, num_nodes=M, embed_dim=3, in_dims=d,out_dims=d)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(2) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d)\n",
    "\n",
    "        self.linear_time = nn.Linear(30, 1)\n",
    "        self.linear_feat = nn.Linear(M * d, 1)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x, loss, gates = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            list_independent_x = []\n",
    "            for i in range(self.M):\n",
    "                if self.type_model == 'LSTM':\n",
    "                    independent_x,_ = self.indenpendet_layer[i](x[:, i, :, :])\n",
    "                else:\n",
    "                    independent_x = self.indenpendet_layer[i](x[:, i, :, :])\n",
    "                independent_x = self.list_ln[i](x[:, i, :, :] + independent_x)\n",
    "                \n",
    "                list_independent_x.append(independent_x.unsqueeze(1))\n",
    "            independent_x = torch.cat(list_independent_x, dim=1)\n",
    "            independent_x,_,_ = self.dagcn(independent_x)\n",
    "            x = self.FFN(independent_x + x)+ x\n",
    "\n",
    "        out = self.linear_time(x.transpose(2, 3)).squeeze(-1)\n",
    "        out = self.linear_feat(out.reshape(B, -1))\n",
    "        return out, loss, gates,_,_\n",
    "\n",
    "    def print_concat_weights(self):\n",
    "        print('Independent Transformer and DAGCN concat weights:', self.dn_embeddings)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # B,L,D\n",
    "#     model = wo4_Transformer_Model(time_len=32,M=3,list_input_dims=[5,5,5],type_model='TCN')\n",
    "#     out, _, gates = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.644Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wo5_DAGCN\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, num_experts=8, out_channels=10, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "        self.k = 2\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "        self.list_input_dim = list_input_dim\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        for input_dim in list_input_dim:\n",
    "            experts = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                          stride=emb_stride),\n",
    "                nn.Tanh(),\n",
    "                nn.Conv1d(in_channels=out_channels, out_channels=out_channels * num_experts, kernel_size=1))\n",
    "\n",
    "            # gating = nn.Linear(input_dim, num_experts)\n",
    "            # noise = nn.Linear(input_dim,num_experts)\n",
    "\n",
    "            w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "            self.list_m_experts.append(experts)\n",
    "            self.list_m_gating.append(w_gate)\n",
    "            self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, m, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[m]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[m]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_combine_features = []\n",
    "        list_spatial_x = []\n",
    "        list_gates = []\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            list_spatial_x.append(x[:, index, :].unsqueeze(1))\n",
    "            index += dim\n",
    "\n",
    "            B, d, L = input_x.shape\n",
    "            # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "            gates, load = self.noisy_top_k_gating(input_x[:, :, -6:-1].reshape(B, dim * 5), i, self.training)\n",
    "            list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "            # calculate importance loss\n",
    "            importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "            loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "            loss *= loss_coef\n",
    "            out_loss = out_loss + loss\n",
    "\n",
    "            out_raw = self.list_m_experts[i](input_x)  # B,D*E,l\n",
    "            out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "            moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "            list_combine_features.append(moe_out.unsqueeze(1))\n",
    "        combine_features = torch.cat(list_combine_features, dim=1)\n",
    "        gates = torch.cat(list_gates, dim=-1)\n",
    "        return combine_features, out_loss, gates\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((30, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.w_2(F.relu(self.w_1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, input_dim, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=input_dim // num_heads, seq_len=30)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, input_dim // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, input_dim // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d), dim=-1)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "\n",
    "class var_Attention1(nn.Module):\n",
    "    def __init__(self, num_nodes, embed_dim, num_time_steps, in_dims, out_dims, num_layers=1):\n",
    "        super(var_Attention1, self).__init__()\n",
    "\n",
    "        self.w_q = nn.Conv2d(in_channels=num_nodes, out_channels=num_nodes, kernel_size=1, groups=num_nodes)\n",
    "        self.w_k = nn.Conv2d(in_channels=num_nodes, out_channels=num_nodes, kernel_size=1, groups=num_nodes)\n",
    "\n",
    "        self.w_v = nn.Conv2d(in_channels=num_nodes, out_channels=num_nodes, kernel_size=1)\n",
    "        self.w_o = nn.Conv2d(in_channels=num_nodes, out_channels=num_nodes, kernel_size=1)\n",
    "\n",
    "        self.num_time_steps = num_time_steps\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, L, D = x.shape\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            res_x = x\n",
    "            unit = torch.eye(self.num_nodes).to(x.device)\n",
    "\n",
    "            q = F.tanh(self.w_q(x)).reshape(B, M, -1)\n",
    "            k = F.tanh(self.w_k(x)).reshape(B, M, -1)\n",
    "\n",
    "            # q = self.w_q(x).reshape(B, M, -1)\n",
    "            # k = self.w_k(x).reshape(B, M, -1)\n",
    "\n",
    "            d = x.shape[-1]\n",
    "\n",
    "            scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d), dim=-1).reshape(B, M, M) + unit  # B, M, M\n",
    "            A = scores\n",
    "\n",
    "            x = torch.einsum('bnm, bmld -> bnld', A, self.w_v(x))\n",
    "            x = self.w_o(x) + res_x\n",
    "        return x, _, _\n",
    "\n",
    "\n",
    "class var_DAGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, embed_dim, num_time_steps, in_dims, out_dims, num_layers=1):\n",
    "        super(var_DAGCN, self).__init__()\n",
    "        self.num_time_steps = num_time_steps\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 动态空间节点嵌入向量\n",
    "        self.dn_embeddings = nn.Parameter(0.5 * torch.ones(num_nodes,\n",
    "                                                           embed_dim),\n",
    "                                          requires_grad=True)  # [T, N, embed_dim]\n",
    "        self.weights = nn.Parameter(torch.ones(1) / 2, requires_grad=True)  # 可学习的权重参数\n",
    "\n",
    "        self.w_v = nn.Conv2d(in_channels=num_nodes, out_channels=num_nodes, kernel_size=1)\n",
    "        self.w_o = nn.Conv2d(in_channels=num_nodes, out_channels=num_nodes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, L, D = x.shape\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            res_x = x\n",
    "\n",
    "            supports = F.softmax(F.relu(torch.einsum('ne, se -> ns', self.dn_embeddings, self.dn_embeddings)), dim=-1)\n",
    "            unit = torch.eye(self.num_nodes).to(supports.device)\n",
    "            supports = supports + unit\n",
    "\n",
    "            A = supports\n",
    "            x = torch.einsum('nm, bmld -> bnld', A, self.w_v(x))\n",
    "            x = self.w_o(x) + res_x\n",
    "        return x, _, _\n",
    "\n",
    "\n",
    "class wo5_DCMC_Model(nn.Module):\n",
    "    def __init__(self, M, time_len, list_input_dims, d=64, num_layers=1, model_name='DMCM'):\n",
    "        super(wo5_DCMC_Model, self).__init__()\n",
    "        self.M = M\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d)\n",
    "        self.ln = nn.LayerNorm(normalized_shape=(30, d))\n",
    "\n",
    "        self.indenpendet_transformer = nn.ModuleList(\n",
    "            [MultiAttention(input_dim=d, num_hiddens=d, num_heads=8).to(device) for _ in range(M)])\n",
    "        self.indenpendet_FFN = nn.ModuleList([PositionwiseFeedForward(d, d).to(device) for _ in range(M)])\n",
    "\n",
    "        if model_name == 'AGCN':\n",
    "            self.layer = var_DAGCN(num_time_steps=30, num_nodes=M, embed_dim=3, in_dims=d,out_dims=d)\n",
    "        if model_name == 'Attention':\n",
    "            self.layer = var_Attention1(num_time_steps=30, num_nodes=M, embed_dim=3, in_dims=d,out_dims=d)\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(2) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.linear_time = nn.Linear(30, 1)\n",
    "        self.linear_feat = nn.Linear(M * d, 1)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x, loss, gates = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            list_independent_x = []\n",
    "            for i in range(self.M):\n",
    "                # print(x.shape)\n",
    "                independent_x = self.indenpendet_transformer[i](x[:, i, :, :])\n",
    "                independent_x = self.ln(x[:, i, :, :] + independent_x)\n",
    "                independent_x = self.indenpendet_FFN[i](independent_x)\n",
    "                list_independent_x.append(independent_x.unsqueeze(1))\n",
    "            independent_x = torch.cat(list_independent_x, dim=1)\n",
    "\n",
    "            if self.model_name == 'AGCN':\n",
    "                dagcn_x,_,_ = self.layer(independent_x + x)\n",
    "            if self.model_name == 'Attention':\n",
    "                dagcn_x,_,_ = self.layer(independent_x + x)\n",
    "            \n",
    "            # if self.model_name == 'DMCM':\n",
    "            else:\n",
    "                dagcn_x = independent_x + x\n",
    "\n",
    "            x = self.FFN(self.ln(dagcn_x) + x) + x\n",
    "\n",
    "        out = self.linear_time(x.transpose(2, 3)).squeeze(-1)\n",
    "        out = self.linear_feat(out.reshape(B, -1))\n",
    "        return out, loss, gates, _, _\n",
    "\n",
    "    def print_concat_weights(self):\n",
    "        print('Independent Transformer and DAGCN concat weights:', self.dn_embeddings)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # B,L,D\n",
    "#     model = wo5_DCMC_Model(time_len=32,M=3,list_input_dims=[5,5,5],type_name='Attention')\n",
    "#     out, _, gates,_ ,_ = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.645Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wo6_Expert_Linear\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "    q = q.contiguous()\n",
    "    k = k.contiguous()\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, num_experts=4, out_channels=10,k=4, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "        self.k = k\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "        self.list_input_dim = list_input_dim\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        for input_dim in list_input_dim:\n",
    "            experts = nn.Sequential(\n",
    "                # nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                #           stride=emb_stride),\n",
    "                # nn.Tanh(),\n",
    "                # nn.Conv1d(in_channels=out_channels, out_channels=out_channels , kernel_size=1)\n",
    "                nn.Linear(input_dim,out_channels * num_experts)\n",
    "            )\n",
    "            w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "            self.list_m_experts.append(experts)\n",
    "            self.list_m_gating.append(w_gate)\n",
    "            self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, m, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[m]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[m]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_combine_features = []\n",
    "        list_spatial_x = []\n",
    "        list_gates = []\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            list_spatial_x.append(x[:, index, :].unsqueeze(1))\n",
    "            index += dim\n",
    "\n",
    "            B, d, L = input_x.shape\n",
    "            # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "            gates, load = self.noisy_top_k_gating(input_x[:, :, -6:-1].reshape(B, dim * 5), i, self.training)\n",
    "            list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "            # calculate importance loss\n",
    "            importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "            loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "            loss *= loss_coef\n",
    "            out_loss = out_loss + loss\n",
    "\n",
    "            out_raw = self.list_m_experts[i](input_x.permute(0,2,1)).permute(0,2,1)  # B,D*E,l\n",
    "            out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "            moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "            list_combine_features.append(moe_out.unsqueeze(1))\n",
    "        combine_features = torch.cat(list_combine_features, dim=1)\n",
    "        gates = torch.cat(list_gates, dim=-1)\n",
    "        return combine_features, out_loss, gates\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, seq_len, dropout=0.1, gate_mlp=False):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((seq_len, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gate_mlp = gate_mlp\n",
    "        self.gate_linear = nn.Linear(d_in, d_hid)\n",
    "        self.silu = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        if self.gate_mlp == False:\n",
    "            x = self.w_2(F.relu(self.w_1(x)))\n",
    "\n",
    "        else:\n",
    "            x = self.w_2(F.relu(self.w_1(x) * (self.silu(self.gate_linear(x)))))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, seq_len, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_hiddens = num_hiddens\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, num_hiddens, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=num_hiddens // num_heads, seq_len=seq_len)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d), dim=-1)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "\n",
    "class wo6_Expert_Linear(nn.Module):\n",
    "    def __init__(self, M, time_len, list_input_dims, d=64, num_layers=1,num_experts=2, k=2):\n",
    "        super(wo6_Expert_Linear, self).__init__()\n",
    "        self.M = M\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d, num_experts=num_experts, k=k)\n",
    "\n",
    "        time_lens= 32\n",
    "        self.indenpendet_transformer = nn.ModuleList([MultiAttention(input_dim=d, num_hiddens=d, num_heads=8,seq_len=time_lens).to(device) for _ in range(M)])\n",
    "        self.list_ln = nn.ModuleList([nn.LayerNorm(normalized_shape=(time_lens, d)) for _ in range(M)])\n",
    "        self.indenpendet_FFN = nn.ModuleList([PositionwiseFeedForward(d, d, seq_len=time_lens,gate_mlp=True).to(device) for _ in range(M)])\n",
    "\n",
    "        # self.dagcn = Mulit_DAGCN(num_time_steps=30, num_nodes=M, in_dims=d, out_dims=d, cheb_k=3, embed_dim=2)\n",
    "        self.dagcn = Attention_DAGCN(num_time_steps=time_lens, num_nodes=M, embed_dim=5, in_dims=d,out_dims=d)\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=(time_lens, d))\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(1) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d, seq_len=time_lens)\n",
    "        self.FFN2 = PositionwiseFeedForward(d, d, seq_len=time_lens)\n",
    "\n",
    "        self.linear_time = nn.Linear(time_lens, 1)\n",
    "        self.linear_feat = nn.Linear(M * d, 1)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x, loss, gates = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "\n",
    "        for _ in range(self.num_layers):       \n",
    "            list_independent_x = []\n",
    "            for i in range(self.M):\n",
    "                in_x = x[:, i, :, :]\n",
    "\n",
    "                independent_x = self.indenpendet_transformer[i](in_x)\n",
    "                # independent_x = self.list_ln[i](in_x + independent_x)\n",
    "                # independent_x = self.indenpendet_FFN[i](independent_x) + independent_x\n",
    "                independent_x = self.indenpendet_FFN[i](independent_x) + in_x\n",
    "                list_independent_x.append(independent_x.unsqueeze(1))\n",
    "            \n",
    "            independent_x = torch.cat(list_independent_x, dim=1)\n",
    "            # independent_x = self.dagcn(independent_x.permute(0, 2, 1, 3)).permute(0, 2, 1, 3)\n",
    "            \n",
    "            dagcn_x, scores, supports = self.dagcn(independent_x + x)\n",
    "            x = self.FFN2(self.ln2(dagcn_x))+ x\n",
    "            # x = self.FFN2(dagcn_x)+ x\n",
    "            # x = independent_x + x\n",
    "\n",
    "        out = self.linear_time(x.transpose(2, 3)).squeeze(-1)\n",
    "        out = self.linear_feat(out.reshape(B, -1))\n",
    "        return out, loss, gates, scores, supports\n",
    "\n",
    "    def print_concat_weights(self):\n",
    "        print('Independent Transformer and DAGCN concat weights:', self.dn_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.646Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wo7_Expert_MLP\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "    q = q.contiguous()\n",
    "    k = k.contiguous()\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, num_experts=4, out_channels=10,k=4, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "        self.k = k\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "        self.list_input_dim = list_input_dim\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        for input_dim in list_input_dim:\n",
    "            experts = nn.Sequential(\n",
    "                nn.Linear(input_dim,out_channels),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(out_channels,out_channels * num_experts)\n",
    "\n",
    "            )\n",
    "            w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "            self.list_m_experts.append(experts)\n",
    "            self.list_m_gating.append(w_gate)\n",
    "            self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, m, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[m]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[m]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_combine_features = []\n",
    "        list_spatial_x = []\n",
    "        list_gates = []\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            list_spatial_x.append(x[:, index, :].unsqueeze(1))\n",
    "            index += dim\n",
    "\n",
    "            B, d, L = input_x.shape\n",
    "            # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "            gates, load = self.noisy_top_k_gating(input_x[:, :, -6:-1].reshape(B, dim * 5), i, self.training)\n",
    "            list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "            # calculate importance loss\n",
    "            importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "            loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "            loss *= loss_coef\n",
    "            out_loss = out_loss + loss\n",
    "\n",
    "            out_raw = self.list_m_experts[i](input_x.permute(0,2,1)).permute(0,2,1)  # B,D*E,l\n",
    "            out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "            moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "            list_combine_features.append(moe_out.unsqueeze(1))\n",
    "        combine_features = torch.cat(list_combine_features, dim=1)\n",
    "        gates = torch.cat(list_gates, dim=-1)\n",
    "        return combine_features, out_loss, gates\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, seq_len, dropout=0.1, gate_mlp=False):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((seq_len, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gate_mlp = gate_mlp\n",
    "        self.gate_linear = nn.Linear(d_in, d_hid)\n",
    "        self.silu = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        if self.gate_mlp == False:\n",
    "            x = self.w_2(F.relu(self.w_1(x)))\n",
    "\n",
    "        else:\n",
    "            x = self.w_2(F.relu(self.w_1(x) * (self.silu(self.gate_linear(x)))))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, seq_len, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_hiddens = num_hiddens\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, num_hiddens, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=num_hiddens // num_heads, seq_len=seq_len)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        scores = F.softmax(torch.bmm(q, k.transpose(1, 2)) / math.sqrt(d), dim=-1)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "\n",
    "class wo7_Expert_MLP(nn.Module):\n",
    "    def __init__(self, M, time_len, list_input_dims, d=64, num_layers=1,num_experts=2, k=2):\n",
    "        super(wo7_Expert_MLP, self).__init__()\n",
    "        self.M = M\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d, num_experts=num_experts, k=k)\n",
    "\n",
    "        time_lens= 32\n",
    "        self.indenpendet_transformer = nn.ModuleList([MultiAttention(input_dim=d, num_hiddens=d, num_heads=8,seq_len=time_lens).to(device) for _ in range(M)])\n",
    "        self.list_ln = nn.ModuleList([nn.LayerNorm(normalized_shape=(time_lens, d)) for _ in range(M)])\n",
    "        self.indenpendet_FFN = nn.ModuleList([PositionwiseFeedForward(d, d, seq_len=time_lens,gate_mlp=True).to(device) for _ in range(M)])\n",
    "\n",
    "        # self.dagcn = Mulit_DAGCN(num_time_steps=30, num_nodes=M, in_dims=d, out_dims=d, cheb_k=3, embed_dim=2)\n",
    "        self.dagcn = Attention_DAGCN(num_time_steps=time_lens, num_nodes=M, embed_dim=5, in_dims=d,out_dims=d)\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=(time_lens, d))\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(1) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d, seq_len=time_lens)\n",
    "        self.FFN2 = PositionwiseFeedForward(d, d, seq_len=time_lens)\n",
    "\n",
    "        self.linear_time = nn.Linear(time_lens, 1)\n",
    "        self.linear_feat = nn.Linear(M * d, 1)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x, loss, gates = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "\n",
    "        for _ in range(self.num_layers):       \n",
    "            list_independent_x = []\n",
    "            for i in range(self.M):\n",
    "                in_x = x[:, i, :, :]\n",
    "\n",
    "                independent_x = self.indenpendet_transformer[i](in_x)\n",
    "                # independent_x = self.list_ln[i](in_x + independent_x)\n",
    "                # independent_x = self.indenpendet_FFN[i](independent_x) + independent_x\n",
    "                independent_x = self.indenpendet_FFN[i](independent_x) + in_x\n",
    "                list_independent_x.append(independent_x.unsqueeze(1))\n",
    "            \n",
    "            independent_x = torch.cat(list_independent_x, dim=1)\n",
    "            # independent_x = self.dagcn(independent_x.permute(0, 2, 1, 3)).permute(0, 2, 1, 3)\n",
    "            \n",
    "            dagcn_x, scores, supports = self.dagcn(independent_x + x)\n",
    "            x = self.FFN2(self.ln2(dagcn_x))+ x\n",
    "            # x = self.FFN2(dagcn_x)+ x\n",
    "            # x = independent_x + x\n",
    "\n",
    "        out = self.linear_time(x.transpose(2, 3)).squeeze(-1)\n",
    "        out = self.linear_feat(out.reshape(B, -1))\n",
    "        return out, loss, gates, scores, supports\n",
    "\n",
    "    def print_concat_weights(self):\n",
    "        print('Independent Transformer and DAGCN concat weights:', self.dn_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T05:29:21.779479Z",
     "iopub.status.busy": "2025-12-09T05:29:21.779000Z",
     "iopub.status.idle": "2025-12-09T05:29:24.832540Z",
     "shell.execute_reply": "2025-12-09T05:29:24.831630Z",
     "shell.execute_reply.started": "2025-12-09T05:29:21.779423Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "class DAGCN(nn.Module):\n",
    "    def __init__(self, num_time_steps, num_nodes, in_dims, out_dims, cheb_k, embed_dim):\n",
    "        super(DAGCN, self).__init__()\n",
    "        self.num_time_steps = num_time_steps\n",
    "        self.num_nodes = num_nodes\n",
    "        self.cheb_k = cheb_k\n",
    "        self.in_dims = in_dims\n",
    "        self.out_dims = out_dims\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # 动态空间节点嵌入向量\n",
    "        self.dn_embeddings = nn.Parameter(0.01 * torch.zeros(num_time_steps,\n",
    "                                                             num_nodes,\n",
    "                                                             embed_dim),\n",
    "                                          requires_grad=True)  # [T, N, embed_dim]\n",
    "        # Theta = E*W--->(tnd,d)\n",
    "        self.weights_pool = nn.Parameter(torch.randn(embed_dim,\n",
    "                                                     cheb_k,\n",
    "                                                     in_dims,\n",
    "                                                     out_dims))\n",
    "        self.bias_pool = nn.Parameter(torch.randn(embed_dim, out_dims))\n",
    "\n",
    "    def forward(self, x):  # x-->[B,T,N,C]\n",
    "        supports = F.softmax(F.relu(torch.einsum('tne, tse->tns', self.dn_embeddings, self.dn_embeddings)), dim=-1)\n",
    "\n",
    "        unit = torch.stack([torch.eye(self.num_nodes).to(supports.device) for _ in range(self.num_time_steps)])\n",
    "        support_set = [unit, supports]\n",
    "\n",
    "        # default cheb_k = 3\n",
    "        for k in range(2, self.cheb_k):\n",
    "            support_set.append(torch.einsum('tnn, tns->tns', 2 * supports, support_set[-1]) - support_set[-2])\n",
    "        supports = torch.stack(support_set, dim=1)  # [T, cheb_k, N, N]\n",
    "        # print(supports.shape)\n",
    "\n",
    "        # theta\n",
    "        theta = torch.einsum('tnd, dkio->tnkio', self.dn_embeddings, self.weights_pool)  # T, N, cheb_k, dim_in, dim_out\n",
    "        bias = torch.einsum('tnd, do->tno', self.dn_embeddings, self.bias_pool)  # T, N, dim_out\n",
    "        x_g = torch.einsum('tknm, btmc->btknc', supports, x)\n",
    "        x_gconv = torch.einsum('btkni, tnkio->btno', x_g, theta) + bias\n",
    "        return x_gconv  # [B, T, N, dim_out]\n",
    "\n",
    "\n",
    "# 多层GCN的层数（一般2到3层最好）\n",
    "class Mulit_DAGCN(nn.Module):\n",
    "    def __init__(self, num_time_steps, num_nodes, in_dims, out_dims, cheb_k, embed_dim, num_layers=1):\n",
    "        super(Mulit_DAGCN, self).__init__()\n",
    "        assert num_layers >= 1, 'At least one DCRNN layer in the Encoder.'\n",
    "        self.node_num = num_nodes\n",
    "        self.input_dim = in_dims\n",
    "        self.num_layers = num_layers\n",
    "        self.dcrnn_cells = nn.ModuleList()  # 模型列表\n",
    "        self.dcrnn_cells.append(DAGCN(num_time_steps, num_nodes, in_dims, out_dims, cheb_k, embed_dim))\n",
    "        for _ in range(1, num_layers):  # 定义多层\n",
    "            self.dcrnn_cells.append(DAGCN(num_time_steps, num_nodes, in_dims, out_dims, cheb_k, embed_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        state = None\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dcrnn_cells[i](x)\n",
    "        return x  # torch.Size([71, 100, 1])\n",
    "\n",
    "\n",
    "class Attention_DAGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, embed_dim, num_time_steps, num_layers=2, is_Dimension_Reduction=False, out_var_dims = 3):\n",
    "        super(Attention_DAGCN, self).__init__()\n",
    "\n",
    "        if is_Dimension_Reduction == False:\n",
    "            out_var_dims = num_nodes\n",
    "            # self.w_q = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=3, groups=num_nodes)\n",
    "            # self.w_k = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=3, groups=num_nodes)\n",
    "            \n",
    "            self.w_q = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=1)\n",
    "            self.w_k = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=1)\n",
    "\n",
    "        else:\n",
    "            out_var_dims = out_var_dims\n",
    "            self.w_q = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=3)\n",
    "            self.w_k = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=3)\n",
    "\n",
    "        self.w_v = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=1)\n",
    "        self.w_o = nn.Conv2d(in_channels=out_var_dims, out_channels=out_var_dims, kernel_size=1)\n",
    "        self.w_res = nn.Conv2d(in_channels=num_nodes, out_channels=out_var_dims, kernel_size=1)\n",
    "\n",
    "        self.num_time_steps = num_time_steps\n",
    "        self.out_var_dims = out_var_dims\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 动态空间节点嵌入向量\n",
    "        self.dn_embeddings = nn.Parameter(torch.randn(out_var_dims,\n",
    "                                                           embed_dim),\n",
    "                                          requires_grad=True)  # [T, N, embed_dim]\n",
    "        self.weights = nn.Parameter(torch.randn(1) / 2, requires_grad=True)  # 可学习的权重参数\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, M, L, D = x.shape\n",
    "        scores, supports = None, None\n",
    "\n",
    "        res_x = x\n",
    "        for _ in range(self.num_layers):\n",
    "            supports = F.softmax(F.relu(torch.einsum('ne, se -> ns', self.dn_embeddings, self.dn_embeddings)), dim=-1)\n",
    "            unit = torch.eye(self.out_var_dims).to(supports.device)\n",
    "            supports = supports + unit\n",
    "\n",
    "            q = F.tanh(self.w_q(x)).reshape(B, self.out_var_dims, -1)\n",
    "            k = F.tanh(self.w_k(x)).reshape(B, self.out_var_dims, -1)\n",
    "\n",
    "            # q = self.w_q(x).reshape(B, self.out_var_dims, -1)\n",
    "            # k = self.w_k(x).reshape(B, self.out_var_dims, -1)\n",
    "\n",
    "            d = x.shape[-1]\n",
    "            # scores = F.softmax(F.relu(torch.einsum('bnl, bml -> bnm', q, k) - torch.einsum('bnl, bml -> bnm', k, q)) / math.sqrt(d), dim=-1) + unit\n",
    "\n",
    "            scores = F.softmax(torch.bmm(q, k.transpose(1, 2))\n",
    "                               / math.sqrt(d), dim=-1).reshape(B, self.out_var_dims, self.out_var_dims) + unit  # B, M, M\n",
    "            # A = F.softmax(F.relu(scores * supports), dim=-1) + unit\n",
    "\n",
    "            A = F.softmax(self.weights * scores + (1 - self.weights) * supports, dim=-1) + unit\n",
    "            # A = F.softmax(scores, dim=-1) + unit\n",
    "\n",
    "            x = torch.einsum('bnm, bmld -> bnld', A, self.w_v(x))\n",
    "            x = self.w_o(x) + self.w_res(res_x)\n",
    "        return x, scores, supports,self.weights\n",
    "\n",
    "\n",
    "# if __name__ =='__main__':\n",
    "#     x = torch.rand(128, 20, 36, 10) * 2 - 1\n",
    "#     model = Attention_DAGCN(num_time_steps=36, num_nodes=20, embed_dim=5, in_dims=10, out_dims=64, is_Dimension_Reduction=True)\n",
    "#     out, scores, supports = model(x)\n",
    "#     print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T05:45:45.710515Z",
     "iopub.status.busy": "2025-12-09T05:45:45.710123Z",
     "iopub.status.idle": "2025-12-09T05:45:45.757659Z",
     "shell.execute_reply": "2025-12-09T05:45:45.756754Z",
     "shell.execute_reply.started": "2025-12-09T05:45:45.710488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "# from 研究生课题.前沿研究.Chaotic_Net.models.DAGCN import DAGCN, Mulit_DAGCN\n",
    "# from 研究生课题.前沿研究.Chaotic_Net.models.DAGCN import Attention_DAGCN\n",
    "\n",
    "# from einops import rearrange\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "# 生成旋转矩阵\n",
    "def precompute_freqs_cis(atten_dim: int, seq_len: int, theta: float = 10000.0):\n",
    "    theta_i_e = (torch.arange(0, atten_dim, 2)[:(atten_dim // 2)].float() / atten_dim) * -1\n",
    "    freqs = theta ** theta_i_e.to(device)\n",
    "    position = torch.arange(seq_len).to(device)  # [0, 1, 2, 3, ..., seq_len]\n",
    "    freqs = torch.outer(position, freqs).float().to(device)  # 求向量的外积,维度为[seq_len,atten_dim]\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs).to(device)  # 将上一步的结果写成复数的形式,模是1幅角是freqs\n",
    "    return freqs_cis.view(1, 1, seq_len, atten_dim // 2)\n",
    "\n",
    "\n",
    "def apply_rope(q: torch.Tensor, k: torch.Tensor, rotate_vecs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    作用: 将q,k向量分别与旋转向量相乘,得到旋转后的q,k向量q/k_rotated。然后进行点乘得到具有位置信息的attention分数\n",
    "    输入: q->weight_q(input_vecs), k->weight_k(input_vecs), rotaed_vecs->旋转向量\n",
    "    \"\"\"\n",
    "    q = q.contiguous()\n",
    "    k = k.contiguous()\n",
    "\n",
    "    # 计算过程q:[batch_size,atten_heads,seq_len,atten_dim]->q_complex:[b,a_h,s,a_d//2,2]->[b,a_h,s,a_d//2]->[b,a_h,s,a_d//2,2]\n",
    "    q_complex = torch.view_as_complex(\n",
    "        q.float().reshape(*q.shape[:-1], -1, 2))  # [batch_size,atten_heads,seq_len,atten_dim//2,2]\n",
    "    k_complex = torch.view_as_complex(k.float().reshape(*k.shape[:-1], -1, 2))  # 将一个大小为n的向量两两组合形成复数来计算\n",
    "    # 位置编码只和向量的序列位置还有向量本身有关，和batch以及注意力头无关，所以只用关注第二维和第四维\n",
    "\n",
    "    q_rotated = torch.view_as_real(q_complex * rotate_vecs).flatten(\n",
    "        3)  # 恢复成原来的样子，将第三维之后压平，也就是(atten_dim//2,2)->(atten_dim)\n",
    "    k_rotated = torch.view_as_real(k_complex * rotate_vecs).flatten(3)\n",
    "    return q_rotated.type_as(q), k_rotated.type_as(q)\n",
    "\n",
    "\n",
    "class Channel_Embedding(nn.Module):\n",
    "    def __init__(self, list_input_dim, num_experts=4, out_channels=10, k=4, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding, self).__init__()\n",
    "        self.k = k\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "        self.list_input_dim = list_input_dim\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        for input_dim in list_input_dim:\n",
    "            experts = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                          stride=emb_stride),\n",
    "                nn.Tanh(),\n",
    "                nn.Conv1d(in_channels=out_channels, out_channels=out_channels * num_experts, kernel_size=1)\n",
    "            )\n",
    "            # w_gate = nn.Parameter(0.005*torch.randn(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            # w_noise = nn.Parameter(0.005*torch.randn(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "            w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "            self.list_m_experts.append(experts)\n",
    "            self.list_m_gating.append(w_gate)\n",
    "            self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, m, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[m]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[m]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_combine_features = []\n",
    "        list_spatial_x = []\n",
    "        list_gates = []\n",
    "        for i, dim in enumerate(self.list_input_dim):\n",
    "            input_x = x[:, index:index + dim, :]\n",
    "            list_spatial_x.append(x[:, index, :].unsqueeze(1))\n",
    "            index += dim\n",
    "\n",
    "            B, d, L = input_x.shape\n",
    "            # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "            gates, load = self.noisy_top_k_gating(input_x[:, :, -6:-1].reshape(B, dim * 5), i, self.training)\n",
    "            list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "            # calculate importance loss\n",
    "            importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "            loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "            loss *= loss_coef\n",
    "            out_loss = out_loss + loss\n",
    "\n",
    "            out_raw = self.list_m_experts[i](input_x)  # B,D*E,l\n",
    "            out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "            moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "            list_combine_features.append(moe_out.unsqueeze(1))\n",
    "        combine_features = torch.cat(list_combine_features, dim=1)\n",
    "        gates = torch.cat(list_gates, dim=-1)\n",
    "        return combine_features, out_loss, gates\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    ''' A two-feed-forward-layer module '''\n",
    "\n",
    "    def __init__(self, d_in, d_hid, seq_len, dropout=0.1, gate_mlp=False):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
    "        self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
    "        self.layer_norm = nn.LayerNorm((seq_len, d_in), eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gate_mlp = gate_mlp\n",
    "        self.gate_linear = nn.Linear(d_in, d_hid)\n",
    "        self.silu = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        if self.gate_mlp == False:\n",
    "            x = self.w_2(F.relu(self.w_1(x)))\n",
    "\n",
    "        else:\n",
    "            x = self.w_2(F.relu(self.w_1(x) * (self.silu(self.gate_linear(x)))))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x += residual\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, input_dim, num_hiddens, num_heads, seq_len, dropout=0.1):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_hiddens = num_hiddens\n",
    "\n",
    "        self.w_q = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_k = nn.Linear(input_dim, num_hiddens)\n",
    "        self.w_v = nn.Linear(input_dim, num_hiddens)\n",
    "\n",
    "        self.w_o = nn.Linear(num_hiddens, num_hiddens, bias=False)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(atten_dim=num_hiddens // num_heads, seq_len=seq_len)\n",
    "\n",
    "    def transpose_qk_RoPE(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B,num_heads,查询数或者键值对数,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x\n",
    "\n",
    "    def transpose_qkv(self, x, num_heads):\n",
    "        '''\n",
    "        :param x: shape(B,查询数或者键值对数,num_hiddens)\n",
    "        :return:  shape(B*num_heads,查询数或者键值对数,num_heads,num_hiddens/num_heads)      # num_hiddens为num_heads的整数倍\n",
    "        '''\n",
    "        x = x.reshape(x.shape[0], x.shape[1], num_heads, -1)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(-1, x.shape[2], x.shape[3])\n",
    "\n",
    "    def transpose_output(self, x, num_heads):\n",
    "        x = x.reshape(-1, num_heads, x.shape[1], x.shape[2])\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, time_len, input_dim = x.shape\n",
    "        q = self.transpose_qk_RoPE(self.w_q(x), self.num_heads)\n",
    "        k = self.transpose_qk_RoPE(self.w_k(x), self.num_heads)  # B,heads,time_len,dim/heads\n",
    "        xq, xk = apply_rope(q=q, k=k, rotate_vecs=self.freqs_cis)\n",
    "\n",
    "        q = xq.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "        k = xk.reshape(-1, time_len, self.num_hiddens // self.num_heads)\n",
    "\n",
    "        v = self.transpose_qkv(self.w_v(x), self.num_heads)\n",
    "\n",
    "        d = x.shape[-1]\n",
    "        att = F.softmax(torch.bmm(q, k.transpose(1, 2)), dim=-1)\n",
    "        scores = att / math.sqrt(d)\n",
    "\n",
    "        output = torch.bmm(self.drop_out(scores), v)\n",
    "        output_concat = self.transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat), att\n",
    " \n",
    "\n",
    "class model_1(nn.Module):\n",
    "    def __init__(self, M, list_input_dims, d=64, num_layers=1, num_experts=3, k=3,\n",
    "                 pred_len=1, time_len = 32, is_Dimension_Reduction=False,out_var_dims = 3):\n",
    "        super(model_1, self).__init__()\n",
    "\n",
    "        if is_Dimension_Reduction == False:\n",
    "            self.M = M\n",
    "        else:\n",
    "            self.M = out_var_dims\n",
    "            self.w_res = nn.Conv2d(in_channels=M, out_channels=out_var_dims, kernel_size=1)\n",
    "\n",
    "        self.pred_len = pred_len\n",
    "        self.num_layers = num_layers\n",
    "        self.list_input_dims = list_input_dims\n",
    "        self.is_Dimension_Reduction = is_Dimension_Reduction\n",
    "        self.embedding = Channel_Embedding(list_input_dim=self.list_input_dims, out_channels=d, \n",
    "                                           num_experts=num_experts, k=k)\n",
    "\n",
    "        self.time_lens = time_len-2\n",
    "        self.indenpendet_transformer = nn.ModuleList(\n",
    "            [MultiAttention(input_dim=d, num_hiddens=d, num_heads=8, seq_len=self.time_lens).to(device) for _ in range(M)])\n",
    "        self.list_ln = nn.ModuleList([nn.LayerNorm(normalized_shape=(self.time_lens, d)) for _ in range(M)])\n",
    "        self.indenpendet_FFN = nn.ModuleList(\n",
    "            [PositionwiseFeedForward(d, d, seq_len=self.time_lens, gate_mlp=True).to(device) for _ in range(M)])\n",
    "\n",
    "        # self.dagcn = Mulit_DAGCN(num_time_steps=30, num_nodes=M, in_dims=d, out_dims=d, cheb_k=3, embed_dim=2)\n",
    "        self.dagcn = Attention_DAGCN(num_time_steps=self.time_lens, num_nodes=M, embed_dim=5, \n",
    "                                     is_Dimension_Reduction=is_Dimension_Reduction,out_var_dims=out_var_dims)\n",
    "        self.ln2 = nn.LayerNorm(normalized_shape=(self.time_lens, d))\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(1) / 2)  # 可学习的权重参数\n",
    "\n",
    "        self.FFN = PositionwiseFeedForward(d, d, seq_len=self.time_lens)\n",
    "        self.FFN2 = PositionwiseFeedForward(d, d, seq_len=self.time_lens)\n",
    "\n",
    "        self.linear_time = nn.Linear(self.time_lens, pred_len)\n",
    "        # self.linear_time = nn.Linear(pred_len, pred_len)\n",
    "        self.linear_feat = nn.Linear(self.M * d, 1)\n",
    "        # self.linear_feat = nn.Linear(self.M * d, 80)\n",
    "\n",
    "    def forward(self, in_x):\n",
    "        B, _, _ = in_x.shape\n",
    "        x = in_x.permute(0, 2, 1)\n",
    "        x, loss, gates = self.embedding(x)\n",
    "        x = x.transpose(2, 3)  # B,M,L,D\n",
    "        \n",
    "        for _ in range(self.num_layers):\n",
    "            list_multi_attention = []\n",
    "\n",
    "            if self.is_Dimension_Reduction == False:\n",
    "                list_independent_x = []\n",
    "                for i in range(self.M):\n",
    "                    in_x = x[:, i, :, :]\n",
    "\n",
    "                    independent_x, attention_i = self.indenpendet_transformer[i](in_x)\n",
    "                    independent_x = self.list_ln[i](in_x + independent_x)\n",
    "                    independent_x = self.indenpendet_FFN[i](independent_x) + independent_x\n",
    "                    list_independent_x.append(independent_x.unsqueeze(1))\n",
    "                    list_multi_attention.append(attention_i.unsqueeze(1))\n",
    "                    \n",
    "                independent_x = torch.cat(list_independent_x, dim=1)\n",
    "                independent_x = self.dagcn(independent_x.permute(0, 2, 1, 3)).permute(0, 2, 1, 3)\n",
    "\n",
    "                dagcn_x, scores, supports,weights = self.dagcn(independent_x + x)\n",
    "                dagcn_x = self.FFN2(self.ln2(dagcn_x + x)) + x\n",
    "                # dagcn_x = self.FFN2(dagcn_x) + x\n",
    "\n",
    "            else:\n",
    "                dagcn_x = x\n",
    "                dagcn_x, scores, supports = self.dagcn(dagcn_x)\n",
    "                dagcn_x = self.FFN2(self.ln2(dagcn_x)) + self.w_res(x)\n",
    "\n",
    "                list_independent_x = []\n",
    "                for i in range(self.M):\n",
    "                    in_x = dagcn_x[:, i, :, :]\n",
    "\n",
    "                    independent_x = self.indenpendet_transformer[i](in_x)\n",
    "                    independent_x = self.list_ln[i](in_x + independent_x)\n",
    "                    independent_x = self.indenpendet_FFN[i](independent_x) + independent_x\n",
    "                    list_independent_x.append(independent_x.unsqueeze(1))\n",
    "\n",
    "                dagcn_x = torch.cat(list_independent_x, dim=1) + self.w_res(x)\n",
    "                \n",
    "            multi_attention = torch.cat(list_multi_attention, dim=1)\n",
    "\n",
    "            # x = self.FFN2(dagcn_x)+ x\n",
    "            # x = independent_x + x\n",
    "\n",
    "        # print(x.shape)\n",
    "        out = self.linear_feat(dagcn_x.permute(0,2,1,3).reshape(B,self.time_lens,-1)).squeeze(-1)\n",
    "        # out = out[:,-self.pred_len:]\n",
    "        out = self.linear_time(out)\n",
    "\n",
    "\n",
    "        # KS\n",
    "        # out = self.linear_feat(dagcn_x.permute(0,2,1,3).reshape(B,self.time_lens,-1)).permute(0,2,1)\n",
    "        # # out = self.linear_time(out).squeeze(-1)\n",
    "        # out = out[:,:,-self.pred_len:].squeeze(-1)\n",
    "        # print(gates)\n",
    "        # print(weights)\n",
    "\n",
    "        return out, loss, gates, _, _, multi_attention\n",
    "        # return out, loss, gates, scores, supports, multi_attention\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # B,L,D\n",
    "#     # model = model_1(time_len=32,M=3,list_input_dims=[5,5,5])\n",
    "#     model = model_1(time_len=32,M=5,list_input_dims=[5,4,1,3,2],is_Dimension_Reduction=True,num_layers=2,pred_len=6)\n",
    "\n",
    "#     out, _, gates, scores, supports = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T05:45:57.282291Z",
     "iopub.status.busy": "2025-12-09T05:45:57.281989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 lorenz\n",
      "----------train--------\n",
      "train X shape:torch.Size([2550, 32, 13])\n",
      "train y shape:torch.Size([2550, 10])\n",
      "----------val--------\n",
      "val X shape:torch.Size([450, 32, 13])\n",
      "val y shape:torch.Size([450, 10])\n",
      "----------test--------\n",
      "test X shape:torch.Size([876, 32, 13])\n",
      "test y shape:torch.Size([876, 10])\n",
      "| end of epoch  10 | time:  0.71s  | train loss 0.0006753029| test loss 0.0006284631 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  0.75s  | train loss 0.0003694666| test loss 0.0003166221 \n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### import time\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 环境设置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # 使用gpu\n",
    "batch_size = 128\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 能固定dataloader的结果，使复现结果一致\n",
    "def setup_seed(seed):\n",
    "   torch.manual_seed(seed)\n",
    "   torch.cuda.manual_seed_all(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "   torch.backends.cudnn.deterministic = True\n",
    "setup_seed(20)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def get_all_result(test_y, y_pred):\n",
    "    test_y = np.nan_to_num(test_y)\n",
    "    y_pred = np.nan_to_num(y_pred)\n",
    "    mse = mean_squared_error(test_y,y_pred)\n",
    "    rmse = mean_squared_error(test_y,y_pred)**0.5\n",
    "    mae= mean_absolute_error(test_y,y_pred)\n",
    "    mape = mean_absolute_percentage_error(test_y,y_pred)\n",
    "    r2 = r2_score(test_y,y_pred)\n",
    "\n",
    "    print(f'mse:{mse}, rmse:{rmse}, mae:{mae},mape:{mape},r2:{r2}')\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "  # 确保输入数据长度一致\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"长度不一致：y_true 和 y_pred\")\n",
    "\n",
    "      # 计算MSE\n",
    "    squared_errors = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
    "    return sum(squared_errors) / len(y_true)\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, epoch, train_dataloader, train_seq, type_loss):\n",
    "    model.train()  # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for batch_index,batch_data in enumerate(train_dataloader):\n",
    "        data,targets = batch_data       #7 torch.Size([B, L, D]) torch.Size([B, pred_len])\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, au_loss, gates, scores, supports, multi_attention = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # 防止梯度爆炸或梯度消失问题\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_seq) / batch_size/5 )\n",
    "        if batch_index % log_interval == 0 and batch_index > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            # print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "            #       'lr {:02.6f} | {:5.2f} ms | '\n",
    "            #       'loss {:5.5f}'.format(\n",
    "            #     epoch, batch_index, len(train_seq) // batch_size, scheduler.get_lr()[0],\n",
    "            #                   elapsed * 1000 / log_interval,cur_loss))  # , math.exp(cur_loss)\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(eval_model, dataloader, data_source_x,type_loss):\n",
    "    eval_model.eval()  # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    result = torch.Tensor(0).to(device)\n",
    "    truth = torch.Tensor(0).to(device)\n",
    "    save_gates = torch.Tensor(0).to(device)\n",
    "    save_multi_attention_scores = torch.Tensor(0).to(device)\n",
    "    save_score = torch.Tensor(0).to(device)\n",
    "    save_support = torch.Tensor(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index,dataset in enumerate(dataloader):\n",
    "            data, targets = dataset\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output, au_loss, gates, scores, supports, multi_attention = eval_model(data)\n",
    "\n",
    "            if type_loss == 'mse':\n",
    "                loss = criterion(output, targets)\n",
    "                total_loss +=  len(data)*loss.item()\n",
    "\n",
    "            else:\n",
    "                loss, loss_shape, loss_temporal = dilate_loss(output, targets, alpha=0.8, gamma=0.01, device=device)\n",
    "                total_loss +=  len(data)*loss.item()\n",
    "\n",
    "            result = torch.cat((result.cpu(), output.cpu()),0)  # todo: check this. -> looks good to me\n",
    "            truth = torch.cat((truth.cpu(), targets.cpu()), 0)\n",
    "\n",
    "            if batch_index == 0:\n",
    "                # save_score = torch.cat((save_score.cpu(), scores.cpu()), 0)\n",
    "                # save_support = torch.cat((save_support.cpu(), supports.cpu()), 0)\n",
    "                save_gates = torch.cat((save_gates.cpu(), gates.cpu()), 0)\n",
    "                save_multi_attention_scores = torch.cat((save_multi_attention_scores.cpu(), multi_attention.cpu()), 0)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    \n",
    "            # save_score = torch.cat((save_score.cpu(), scores.cpu()), 0)\n",
    "            # save_support = torch.cat((save_support.cpu(), supports.cpu()), 0)\n",
    "            # save_gates = torch.cat((save_gates.cpu(), gates.cpu()), 0)\n",
    "            # save_multi_attention_scores = torch.cat((save_multi_attention_scores.cpu(), multi_attention.cpu()), 0)\n",
    "        \n",
    "        return total_loss / len(data_source_x),result,truth, save_gates, save_score, save_support, save_multi_attention_scores\n",
    "\n",
    "\n",
    "\n",
    "def get_model(type_name, model_name, load_name, wo4_type_model='MLP',wo5_type_model='DCMC',pred_len=1,time_len=32,num_experts=8,k=2):\n",
    "    model = None        # 定义模型\n",
    "\n",
    "    # wo1_SR\n",
    "    if load_name == 'tr':\n",
    "        if model_name == 'Chaotic-Net':\n",
    "            if type_name == 'lorenz':\n",
    "                model = model_1(time_len=time_len,M=3,list_input_dims=[5,5,5],d=64).to(device)\n",
    "            if type_name == 'rossler':\n",
    "                model = model_1(time_len=time_len,M=3,list_input_dims=[3,5,5],d=128,pred_len=pred_len,num_experts=4,k=4).to(device)\n",
    "            if type_name == 'power':\n",
    "                model = model_1(time_len=time_len,M=6,list_input_dims=[5,5,5,5,5,5],d=32).to(device)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = model_1(time_len=time_len,M=40,list_input_dims=[1]*40,d=32,\n",
    "                                is_Dimension_Reduction=False,out_var_dims=8,num_experts=4,k=2).to(device)\n",
    "            if type_name == 'KS':\n",
    "                model = model_1(time_len=time_len,M=20,list_input_dims=[4]*20,d=32,\n",
    "                                is_Dimension_Reduction=True,out_var_dims=3,num_experts=4,k=1,num_layers=1).to(device)\n",
    "            \n",
    "            if type_name == 'EMD_power':\n",
    "                model = model_1(time_len=32,M=6,list_input_dims=[5,5,7,6,4,5],d=32).to(device)\n",
    "            if type_name == 'EMD_lorenz':\n",
    "                model = model_1(time_len=32,M=3,list_input_dims=[5,5,5],d=64).to(device)    \n",
    "            if type_name == 'EMD_rossler':\n",
    "                model = model_1(time_len=32,M=3,list_input_dims=[3,5,5],d=64).to(device) \n",
    "            \n",
    "            if type_name == 'EMD_power2':\n",
    "                model = model_1(time_len=32,M=6,list_input_dims=[9,9,1,9,10,10],d=32).to(device)\n",
    "            if type_name == 'EMD_lorenz2':\n",
    "                model = model_1(time_len=32,M=3,list_input_dims=[5,6,6],d=64).to(device)    \n",
    "            if type_name == 'EMD_rossler2':\n",
    "                model = model_1(time_len=32,M=3,list_input_dims=[5,5,6],d=32).to(device)\n",
    "            \n",
    "            # if type_name == 'Wave_power2':\n",
    "            #     model = model_1(time_len=32,M=6,list_input_dims=[6,6,6,6,6,6],d=32).to(device)\n",
    "            # if type_name == 'Wave_lorenz2':\n",
    "            #     model = model_1(time_len=32,M=3,list_input_dims=[6,6,6],d=64).to(device)    \n",
    "                \n",
    "            if type_name == 'Wave_power':\n",
    "                model = model_1(time_len=32,M=6,list_input_dims=[6,6,6,6,6,6],d=32).to(device)\n",
    "            if type_name == 'Wave_lorenz':\n",
    "                model = model_1(time_len=32,M=3,list_input_dims=[6,6,6],d=64).to(device)\n",
    "            if type_name == 'Wave_rossler':\n",
    "                model = model_1(time_len=32,M=3,list_input_dims=[6,6,6],d=32).to(device)\n",
    "            \n",
    "                        \n",
    "        if model_name == 'wo2_MoEE':\n",
    "            if type_name == 'rossler':\n",
    "                model = wo2_MoEE_Model(time_len=time_len,M=3,list_input_dims=[3,5,5],d=64).to(device)\n",
    "        if model_name == 'wo6_Expert_Linear':\n",
    "            if type_name == 'rossler':\n",
    "                model = wo6_Expert_Linear(time_len=time_len,M=3,list_input_dims=[3,5,5],d=64).to(device)\n",
    "        if model_name == 'wo7_Expert_MLP':\n",
    "            if type_name == 'rossler':\n",
    "                model = wo7_Expert_MLP(time_len=32,M=3,list_input_dims=[3,5,5],d=64).to(device)\n",
    "\n",
    "        # wo3_independent\n",
    "        if model_name == 'wo3_independent':\n",
    "            if type_name == 'rossler':\n",
    "                model = wo3_independent_Model(time_len=32,M=3,list_input_dims=[3,5,5],d=64)\n",
    "        if model_name == 'wo4_Transformer':\n",
    "            if type_name == 'rossler':\n",
    "                model = wo4_Transformer_Model(time_len=32,M=3,list_input_dims=[3,5,5],type_model=wo4_type_model,d=64)\n",
    "        if model_name == 'wo5_DAGCN':\n",
    "            if type_name == 'rossler':\n",
    "                model = wo5_DCMC_Model(time_len=32,M=3,list_input_dims=[3,5,5],d=64,model_name=wo5_type_model)\n",
    "                \n",
    "    else:\n",
    "        # Chaotic-Net\n",
    "        if model_name == 'Chaotic-Net':\n",
    "            if type_name == 'lorenz':\n",
    "                model = model_1(time_len=time_len,M=3,list_input_dims=[5,5,5],d=128,num_layers=1,\n",
    "                                num_experts=num_experts,k=k,pred_len=pred_len).to(device)\n",
    "                \n",
    "            if type_name == 'power':\n",
    "                model = model_1(time_len=time_len,M=6,list_input_dims=[5,5,5,5,5,5],d=128,\n",
    "                                num_experts=num_experts,k=k,pred_len=pred_len,\n",
    "                                is_Dimension_Reduction=False).to(device)  \n",
    "            \n",
    "        # wo2_WoEE\n",
    "        if model_name == 'wo2_MoEE':\n",
    "            if type_name == 'lorenz':\n",
    "                model = wo2_MoEE_Model(time_len=32,M=3,list_input_dims=[5,5,5],d=64)\n",
    "            if type_name == 'power':\n",
    "                model = wo2_MoEE_Model(time_len=32,M=6,list_input_dims=[5,5,5,5,5,5],d=32)\n",
    "            \n",
    "        # wo3_independent\n",
    "        if model_name == 'wo3_independent':\n",
    "            if type_name == 'lorenz':\n",
    "                model = wo3_independent_Model(time_len=32,M=3,list_input_dims=[5,5,5],d=64)\n",
    "            if type_name == 'power':\n",
    "                model = wo3_independent_Model(time_len=32,M=6,list_input_dims=[5,5,5,5,5,5],d=32)\n",
    "\n",
    "        # wo4_Transformer\n",
    "        if model_name == 'wo4_Transformer':\n",
    "            if type_name == 'lorenz':\n",
    "                model = wo4_Transformer_Model(time_len=32,M=3,list_input_dims=[5,5,5],type_model=wo4_type_model,d=64)\n",
    "            if type_name == 'power':\n",
    "                model = wo4_Transformer_Model(time_len=32,M=6,list_input_dims=[5,5,5,5,5,5],type_model=wo4_type_model,d=32)\n",
    "\n",
    "        # wo5_DAGCN\n",
    "        if model_name == 'wo5_DAGCN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = wo5_DCMC_Model(time_len=32,M=3,list_input_dims=[5,5,5],d=64,model_name=wo5_type_model)\n",
    "            if type_name == 'power':\n",
    "                model = wo5_DCMC_Model(time_len=32,M=6,list_input_dims=[5,5,5,5,5,5],d=32,model_name=wo5_type_model)\n",
    "\n",
    "        # wo6_Expert_Linear\n",
    "        if model_name == 'wo6_Expert_Linear':\n",
    "            if type_name == 'lorenz':\n",
    "                model = wo6_Expert_Linear(time_len=32,M=3,list_input_dims=[5,5,5],d=64)\n",
    "            if type_name == 'power':\n",
    "                model = wo6_Expert_Linear(time_len=32,M=6,list_input_dims=[5,5,5,5,5,5],d=32)\n",
    "                \n",
    "        # wo7_Expert_MLP\n",
    "        if model_name == 'wo7_Expert_MLP':\n",
    "            if type_name == 'lorenz':\n",
    "                model = wo7_Expert_MLP(time_len=32,M=3,list_input_dims=[5,5,5],d=64)\n",
    "            if type_name == 'power':\n",
    "                model = wo7_Expert_MLP(time_len=32,M=6,list_input_dims=[5,5,5,5,5,5],d=32)\n",
    "    return model\n",
    "\n",
    "\n",
    "def read_npy(type_name,load_name,model_name,epochs,weight_decay,lr = 0.001,wo4_type_model='MLP',\n",
    "             wo5_type_model='DCMC',seed=0,pred_len=1,time_len=32,num_experts=2,k=2):\n",
    "    setup_seed(seed)\n",
    "    if pred_len == 1:\n",
    "        if load_name == 'sr':\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/sr_{}_{}.npy'.format(type_name,seed),allow_pickle=True).item()\n",
    "        else:\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_{}_{}.npy'.format(type_name,seed),allow_pickle=True).item()\n",
    "        # saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_KS_42.npy',allow_pickle=True).item()\n",
    "\n",
    "    else:\n",
    "        if load_name == 'sr':\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/sr_{}_{}_({}).npy'.format(type_name,seed,pred_len),allow_pickle=True).item()\n",
    "        else:\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_{}_{}_({}).npy'.format(type_name,seed,pred_len),allow_pickle=True).item()\n",
    "\n",
    "    # saved_dict = np.load(r'/kaggle/input/original-chaotic-data/sr_{}_({}_{}).npy'.format(type_name,time_len,pred_len),allow_pickle=True).item()\n",
    "    \n",
    "    \n",
    "    train_seq = saved_dict['train']['train_seq'].to(device)\n",
    "    train_label = saved_dict['train']['train_label'].to(device)\n",
    "    train_dataloader = saved_dict['train']['train_dataloader']\n",
    "\n",
    "    val_seq = saved_dict['val']['val_seq'].to(device)\n",
    "    val_label = saved_dict['val']['val_label'].to(device)\n",
    "    val_dataloader = saved_dict['val']['val_dataloader']\n",
    "\n",
    "    test_seq = saved_dict['test']['test_seq'].to(device)\n",
    "    test_label = saved_dict['test']['test_label'].to(device)\n",
    "    test_dataloader = saved_dict['test']['test_dataloader']\n",
    "\n",
    "    print('----------train--------')\n",
    "    print(f'train X shape:{train_seq.shape}')\n",
    "    print(f'train y shape:{train_label.shape}')\n",
    "\n",
    "    print('----------val--------')\n",
    "    print(f'val X shape:{val_seq.shape}')\n",
    "    print(f'val y shape:{val_label.shape}')\n",
    "\n",
    "    print('----------test--------')\n",
    "    print(f'test X shape:{test_seq.shape}')\n",
    "    print(f'test y shape:{test_label.shape}')\n",
    "    \n",
    "    model = get_model(type_name, model_name, load_name, wo4_type_model=wo4_type_model,wo5_type_model=wo5_type_model,\n",
    "                      pred_len=pred_len,time_len=time_len,num_experts=num_experts,k=k).to(device)\n",
    "    \n",
    "    type_loss = 'mse'\n",
    "    # type_loss = 'dilate'\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.98)       # 学习率调度器对象,调度器会在每个10个epoch后将学习率乘以gamma。\n",
    "    best_test_loss = 1000\n",
    "    best_val_output, best_val_target,best_test_output, best_test_target = 0, 0, 0, 0\n",
    "    best_train_save_gates, best_test_save_gates, best_train_attention_scores, best_test_attention_scores = 0, 0, 0, 0\n",
    "    best_train_save_scores, best_test_save_scores, best_train_save_supports, best_test_save_supports = 0, 0, 0, 0\n",
    "\n",
    "    best_model = None\n",
    "    list_train_loss, list_test_loss = [], []\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_model = train(model, optimizer, scheduler, epoch,train_dataloader, train_seq,type_loss)\n",
    "\n",
    "        train_loss, train_output, train_target,train_save_gates, train_save_score, train_save_support, train_multi_attention_scores = evaluate(train_model, train_dataloader, train_seq,type_loss)\n",
    "        test_loss, test_output, test_target,test_save_gates, test_save_score, test_save_support, test_multi_attention_scores = evaluate(train_model, test_dataloader, test_seq,type_loss)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_test_loss.append(test_loss)\n",
    "\n",
    "        if test_loss<best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_test_output = test_output\n",
    "            best_test_target = test_target\n",
    "            best_model = train_model\n",
    "            \n",
    "            best_train_save_gates = train_save_gates\n",
    "            best_test_save_gates = test_save_gates\n",
    "            best_train_attention_scores = train_multi_attention_scores\n",
    "            best_test_attention_scores = test_multi_attention_scores\n",
    "\n",
    "            best_train_save_scores = train_save_score\n",
    "            best_test_save_scores = test_save_score\n",
    "            best_train_save_supports = train_save_support\n",
    "            best_test_save_supports = test_save_support\n",
    "\n",
    "\n",
    "        if epoch%10==0:\n",
    "            print(\n",
    "                '| end of epoch {:3d} | time: {:5.2f}s  | train loss {:.10f}| test loss {:.10f} '.format(\n",
    "                    epoch, (time.time() - epoch_start_time), train_loss, test_loss))\n",
    "            print('-' * 90)\n",
    "\n",
    "        scheduler.step()        # 学习率调度器对象\n",
    "\n",
    "    # data_out = pd.DataFrame({'true':[i[0] for i in best_test_target.tolist()],\n",
    "    #                          'pred':[i[0] for i in best_test_output.tolist()]},\n",
    "    #                         index=range(len(best_test_output)))\n",
    "    \n",
    "    # torch.save(best_model.state_dict(),r'/kaggle/working/best_model_{}.pth'.format(type_name))\n",
    "\n",
    "    # print(data_out)\n",
    "    # print(mean_squared_error(best_test_target,best_test_output))\n",
    "    # print('train:',train_save_gates)\n",
    "    \n",
    "    # out_information = {\n",
    "    #     'train_gates':best_train_save_gates,'test_gates':best_test_save_gates,\n",
    "    #     'train_multi_attention_scores':best_train_attention_scores,'test_multi_attention_scores':best_test_attention_scores,\n",
    "    #     'train_score':best_test_save_scores, 'test_score':best_test_save_scores, \n",
    "    #     'train_support':best_train_save_supports, 'test_support':best_test_save_supports, \n",
    "    #                   }\n",
    "    # print(best_test_save_scores,best_test_save_scores.shape,best_test_save_supports)\n",
    "\n",
    "\n",
    "    if type_name!='KS':\n",
    "        if pred_len == 1:\n",
    "            data_out = pd.DataFrame({'true':[i[0] for i in best_test_target.tolist()],\n",
    "                                 'pred':[i[0] for i in best_test_output.tolist()]},\n",
    "                                index=range(len(best_test_output)))\n",
    "            \n",
    "            get_all_result(data_out['true'], data_out['pred'])\n",
    "            if model_name == 'wo4_Transformer':\n",
    "                data_out.to_csv(r'/kaggle/working/{}_{}_{}_{}_{}.csv'.format(load_name,type_name,model_name,wo4_type_model,seed))\n",
    "            if model_name == 'wo5_DAGCN':\n",
    "                data_out.to_csv(r'/kaggle/working/{}_{}_{}_{}_{}.csv'.format(load_name,type_name,model_name,wo5_type_model,seed))\n",
    "            else:\n",
    "                folder_path = '/kaggle/working/new2/'\n",
    "                if not os.path.exists(folder_path):\n",
    "                    os.makedirs(folder_path)\n",
    "                file_path = os.path.join(folder_path, '{}_{}_{}_MOEE_{}_{}.csv'.format(load_name,type_name,model_name,num_experts,k))\n",
    "                print(file_path)\n",
    "                data_out.to_csv(file_path)\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            columns = ['true{}'.format(i+1) for i in range(pred_len)]\n",
    "            columns.extend(['pred{}'.format(i+1) for i in range(pred_len)])\n",
    "            true_df = pd.DataFrame(best_test_target.numpy(), columns=columns[:pred_len])\n",
    "            pred_df = pd.DataFrame(best_test_output.numpy(), columns=columns[pred_len:])\n",
    "            data_out = pd.concat([true_df, pred_df], axis=1)\n",
    "            print(data_out)\n",
    "            get_all_result(true_df, pred_df)\n",
    "            \n",
    "            data_out.to_csv(r'/kaggle/working/{}_{}_{}_{}_({}).csv'.format(load_name,type_name,model_name,seed,pred_len))\n",
    "            # data_out.to_csv(r'/kaggle/working/{}_{}_{}_({}_{}).csv'.format(load_name,type_name,model_name,time_len,pred_len))\n",
    "\n",
    "    else:\n",
    "        columns = ['true{}'.format(i+1) for i in range(80)]\n",
    "        columns.extend(['pred{}'.format(i+1) for i in range(80)])\n",
    "        true_df = pd.DataFrame(best_test_target.numpy(), columns=columns[:80])\n",
    "        pred_df = pd.DataFrame(best_test_output.numpy(), columns=columns[80:])\n",
    "        data_out = pd.concat([true_df, pred_df], axis=1)\n",
    "        print(data_out,111)\n",
    "        \n",
    "        get_all_result(true_df, pred_df)\n",
    "        file_name = r'{}_{}_{}.csv'.format(load_name,type_name,model_name,time_len,pred_len)\n",
    "        data_out.to_csv(file_name)\n",
    "        \n",
    "\n",
    "    # np.save(r'/kaggle/working/{}_{}_information.npy'.format(load_name,type_name), out_information)\n",
    "\n",
    "    # plt.plot(best_test_target, label='真实值')\n",
    "    # plt.plot(best_test_output, label='预测值')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "models = ['Chaotic-Net','wo2_MoEE','wo3_independent','wo4_Transformer','wo5_DAGCN', 'wo6_Expert_Linear', 'wo7_Expert_MLP']\n",
    "load_name = 'sr'\n",
    "\n",
    "\n",
    "# read_npy('power',load_name,models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=1,num_experts=8,k=6)\n",
    "# read_npy('power',load_name,models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=1,num_experts=8,k=7)\n",
    "# read_npy('power',load_name,models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=1,num_experts=8,k=8)\n",
    "\n",
    "\n",
    "# for num in [8]:\n",
    "#     for k in [1,2,3,4,5,6,7,8]:\n",
    "#         if num<k:\n",
    "#             continue\n",
    "#         else:\n",
    "#             print(num,k)\n",
    "#             # read_npy('lorenz',load_name,models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=1,num_experts=num,k=k)\n",
    "#             read_npy('power',load_name,models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=1,num_experts=num,k=k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read_npy('lorenz',load_name,models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=1)\n",
    "# read_npy('rossler','tr',models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=1)\n",
    "# read_npy('power',load_name,models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=1)\n",
    "\n",
    "\n",
    "# for time_len in [8,16,24,32,40,48,56,64]:    \n",
    "# for time_len in [40]:    \n",
    "#     print(time_len,'lorenz')\n",
    "#     read_npy('power','sr',models[0],epochs = 300, weight_decay=2,lr = 0.001,seed=42,pred_len=6,time_len=time_len)\n",
    "    # read_npy('lorenz','sr',models[0],epochs = 300, weight_decay=0.02,lr = 0.005,seed=42,pred_len=6,time_len=time_len)\n",
    "\n",
    "\n",
    "\n",
    "for pred_len in [10,11,12,4,5,6,7,8,9]:\n",
    "    print(pred_len,'lorenz')\n",
    "    # read_npy('power','sr',models[0],epochs = 3, weight_decay=0.5,lr = 0.001,seed=42,pred_len=pred_len)\n",
    "    read_npy('rossler','tr',models[0],epochs = 300, weight_decay=0.02,lr = 0.005,seed=42,pred_len=pred_len)\n",
    "\n",
    "\n",
    "# for i in [1]:\n",
    "#     print(i,'rossler')\n",
    "    # read_npy('lorenz-96','tr',models[0],epochs = 300, weight_decay=1.2,lr = 0.005,seed=i)\n",
    "    # read_npy('KS','tr',models[0],epochs = 300, weight_decay=1.2,lr = 0.005,seed=42)\n",
    "\n",
    "    # read_npy('rossler','tr',models[2],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)\n",
    "    # read_npy('power','sr',models[2],epochs = 300, weight_decay=0.5,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "    # read_npy('power','sr',models[4], epochs = 300, weight_decay=0.5, lr = 0.001, seed=i, wo5_type_model='AGCN')\n",
    "    # read_npy('power','sr',models[4], epochs = 300, weight_decay=0.5, lr = 0.001, seed=i, wo5_type_model='Attention')\n",
    "    # read_npy('power','sr',models[4], epochs = 300, weight_decay=0.5, lr = 0.001, seed=i, wo5_type_model='DMCM')\n",
    "\n",
    "\n",
    "    # read_npy('rossler','tr',models[4], epochs = 300, weight_decay=0.02, lr = 0.001, seed=i, wo5_type_model='AGCN')\n",
    "    # read_npy('rossler','tr',models[4], epochs = 300, weight_decay=0.02, lr = 0.001, seed=i, wo5_type_model='Attention')\n",
    "    # read_npy('rossler','tr',models[4], epochs = 300, weight_decay=0.02, lr = 0.001, seed=i, wo5_type_model='DMCM')\n",
    "\n",
    "\n",
    "    # read_npy('lorenz','sr',models[3],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i,wo4_type_model='TCN')\n",
    "    # read_npy('lorenz','sr',models[3],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i,wo4_type_model='LSTM')\n",
    "\n",
    "    # read_npy('power','sr',models[3],epochs = 300, weight_decay=0.5,lr = 0.001,seed=i,wo4_type_model='TCN')\n",
    "    # read_npy('power','sr',models[3],epochs = 300, weight_decay=0.5,lr = 0.001,seed=i,wo4_type_model='LSTM')\n",
    "\n",
    "    # read_npy('rossler','tr',models[-2],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)\n",
    "    # read_npy('rossler','tr',models[-1],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)\n",
    "    # read_npy('Wave_rossler','tr',models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.647Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# for i in [1,2,3,4,5]:\n",
    "#     print(i,'Wave_lorenz2')\n",
    "#     read_npy('Wave_lorenz2','tr',models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "# for i in [1,2,3,4,5]:\n",
    "#     print(i,'EMD_lorenz2')\n",
    "#     read_npy('EMD_lorenz2','tr',models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "# for i in [2,3,4,5]:\n",
    "#     print(i,'Wave_power')\n",
    "#     read_npy('Wave_power','tr',models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "# for i in [1,2,3,4,5]:\n",
    "#     print(i,'EMD_power2')\n",
    "#     read_npy('EMD_power2','tr',models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "# for i in [1,2,3,4,5]:\n",
    "#     print(i,'EMD_power')\n",
    "#     read_npy('EMD_power','tr',models[0],epochs = 300, weight_decay=0.5,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "# for i in [1,2,3,4,5]:\n",
    "#     print(i,'EMD_lorenz')\n",
    "#     read_npy('EMD_lorenz','tr',models[0],epochs = 300, weight_decay=0.02,lr = 0.001,seed=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T06:09:59.104795Z",
     "iopub.status.busy": "2025-12-08T06:09:59.104463Z",
     "iopub.status.idle": "2025-12-08T06:09:59.125194Z",
     "shell.execute_reply": "2025-12-08T06:09:59.124316Z",
     "shell.execute_reply.started": "2025-12-08T06:09:59.104769Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "# from 研究生课题.前沿研究.Chaotic_Net.models.DAGCN import DAGCN, Mulit_DAGCN\n",
    "# from 研究生课题.前沿研究.Chaotic_Net.models.DAGCN import Attention_DAGCN\n",
    "\n",
    "# from einops import rearrange\n",
    "from typing import Union, Tuple\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "torch.manual_seed(21)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用gpu\n",
    "\n",
    "\n",
    "class Channel_Embedding_ablation(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts=4, out_channels=10, k=4, emb_kernel_size=3, emb_stride=1):\n",
    "        super(Channel_Embedding_ablation, self).__init__()\n",
    "        self.k = k\n",
    "        self.noisy_gating = True\n",
    "        self.num_experts = num_experts\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.list_m_experts = nn.ModuleList()\n",
    "        self.list_m_gating = []\n",
    "        self.list_m_noise = []\n",
    "\n",
    "        experts = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=out_channels, kernel_size=emb_kernel_size,\n",
    "                      stride=emb_stride),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels=out_channels, out_channels=out_channels * num_experts, kernel_size=1)\n",
    "        )\n",
    "        # w_gate = nn.Parameter(0.005*torch.randn(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "        # w_noise = nn.Parameter(0.005*torch.randn(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "        w_gate = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "        w_noise = nn.Parameter(torch.zeros(input_dim * 5, num_experts), requires_grad=True).to(device)\n",
    "\n",
    "        self.list_m_experts.append(experts)\n",
    "        self.list_m_gating.append(w_gate)\n",
    "        self.list_m_noise.append(w_noise)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert (self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"计算样本变异系数\n",
    "        The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`(标量).\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean() ** 2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in) / noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out) / noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.list_m_gating[0]  # 计算每个expert的权重\n",
    "        if self.noisy_gating and train:  # 在训练中加入残差等\n",
    "            raw_noise_stddev = x @ self.list_m_noise[0]  # 根据输入数据设置噪声权重\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        logits = self.softmax(logits)\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = top_k_logits / (top_k_logits.sum(1, keepdim=True) + 1e-6)  # normalization\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        index, out_loss = 0, 0\n",
    "        list_gates = []\n",
    "\n",
    "        B, d, L = x.shape\n",
    "        # gates, load = self.noisy_top_k_gating(input_x[:,:,-1], i, self.training)\n",
    "        gates, load = self.noisy_top_k_gating(x[:, :, -6:-1].reshape(B, d*5), self.training)\n",
    "        list_gates.append(gates.unsqueeze(-1))\n",
    "\n",
    "        # calculate importance loss\n",
    "        importance = gates.sum(0)  # 将每个expert的gates权重加和,计算总的贡献值\n",
    "        loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "        loss *= loss_coef\n",
    "        out_loss = out_loss + loss\n",
    "\n",
    "        out_raw = self.list_m_experts[0](x)  # B,D*E,l\n",
    "        out_raw = out_raw.permute(0, 2, 1).reshape(B, -1, self.out_channels, self.num_experts)  # B,l,D,E\n",
    "\n",
    "        moe_out = torch.einsum(\"BLDE,BE->BLD\", out_raw, gates).permute(0, 2, 1)\n",
    "\n",
    "        return moe_out\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#         x = torch.randn((128, 15, 32))\n",
    "#         model = Channel_Embedding_ablation(input_dim=15)\n",
    "#         out = model(x)\n",
    "#         print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.649Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim, hidden_dim1, hidden_dim2, pred_len,num_experts=2,k=2):\n",
    "        # def __init__(self, seq_len, input_dim, hidden_dim1, hidden_dim2, pred_len):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim1, hidden_dim2, batch_first=True)\n",
    "        # self.dropout2 = nn.Dropout(0.2)\n",
    "        self.lstm3 = nn.LSTM(hidden_dim2, hidden_dim2, batch_first=True)\n",
    "        self.fc_feature = nn.Linear(hidden_dim2, 1)\n",
    "        # self.fc_feature = nn.Linear(hidden_dim2, 80)\n",
    "\n",
    "        self.fc_time = nn.Linear(seq_len, pred_len)\n",
    "\n",
    "        self.embedding = Channel_Embedding_ablation(input_dim, out_channels=input_dim, num_experts=num_experts, k=k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, _, _ = x.shape\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1, 2)  # B,M,L,D\n",
    "\n",
    "        # x = x.permute(0,2,1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        # x = self.dropout2(x) # Uncomment if needed\n",
    "        x, _ = self.lstm3(x)\n",
    "        # Flatten the output for the Dense layer\n",
    "\n",
    "        x = self.fc_feature(x).squeeze(-1)\n",
    "        x = self.fc_time(x)\n",
    "\n",
    "        # x = self.fc_feature(x).permute(0,2,1)\n",
    "        # x = self.fc_time(x).squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15)).to(devide)        # [B, L, D]\n",
    "#     model = LSTM_Model(seq_len=30,input_dim=15, hidden_dim1=128, hidden_dim2=64, pred_len=1)\n",
    "#     out = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.649Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
    "                                  out_channels=c_in,\n",
    "                                  kernel_size=3,\n",
    "                                  padding=2,\n",
    "                                  padding_mode='circular')\n",
    "        self.norm = nn.BatchNorm1d(c_in)\n",
    "        self.activation = nn.ELU()\n",
    "        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downConv(x.permute(0, 2, 1))\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxPool(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        new_x, attn = self.attention(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )\n",
    "        x = x + self.dropout(new_x)\n",
    "\n",
    "        y = x = self.norm1(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm2(x + y), attn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
    "        self.norm = norm_layer\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # x [B, L, D]\n",
    "        attns = []\n",
    "        if self.conv_layers is not None:\n",
    "            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n",
    "                delta = delta if i == 0 else None\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                x = conv_layer(x)\n",
    "                attns.append(attn)\n",
    "            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n",
    "            attns.append(attn)\n",
    "        else:\n",
    "            for attn_layer in self.attn_layers:\n",
    "                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n",
    "                attns.append(attn)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        return x, attns\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
    "                 dropout=0.1, activation=\"relu\"):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        x = x + self.dropout(self.self_attention(\n",
    "            x, x, x,\n",
    "            attn_mask=x_mask,\n",
    "            tau=tau, delta=None\n",
    "        )[0])\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x = x + self.dropout(self.cross_attention(\n",
    "            x, cross, cross,\n",
    "            attn_mask=cross_mask,\n",
    "            tau=tau, delta=delta\n",
    "        )[0])\n",
    "\n",
    "        y = x = self.norm2(x)\n",
    "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "\n",
    "        return self.norm3(x + y)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers, norm_layer=None, projection=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        self.projection = projection\n",
    "\n",
    "    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "\n",
    "        if self.projection is not None:\n",
    "            x = self.projection(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "class TriangularCausalMask():\n",
    "    def __init__(self, B, L, device=\"cpu\"):\n",
    "        mask_shape = [B, 1, L, L]\n",
    "        with torch.no_grad():\n",
    "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "class ProbMask():\n",
    "    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n",
    "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
    "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
    "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
    "                    torch.arange(H)[None, :, None],\n",
    "                    index, :].to(device)\n",
    "        self._mask = indicator.view(scores.shape).to(device)\n",
    "\n",
    "    @property\n",
    "    def mask(self):\n",
    "        return self._mask\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from reformer_pytorch import LSHSelfAttention\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "\n",
    "class DSAttention(nn.Module):\n",
    "    '''De-stationary Attention'''\n",
    "\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(DSAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "\n",
    "        tau = 1.0 if tau is None else tau.unsqueeze(\n",
    "            1).unsqueeze(1)  # B x 1 x 1 x 1\n",
    "        delta = 0.0 if delta is None else delta.unsqueeze(\n",
    "            1).unsqueeze(1)  # B x 1 x 1 x S\n",
    "\n",
    "        # De-stationary Attention, rescaling pre-softmax score with learned de-stationary factors\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys) * tau + delta\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "\n",
    "\n",
    "class FullAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(FullAttention, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, H, E = queries.shape\n",
    "        _, S, _, D = values.shape\n",
    "        scale = self.scale or 1. / sqrt(E)\n",
    "\n",
    "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n",
    "\n",
    "        if self.mask_flag:\n",
    "            if attn_mask is None:\n",
    "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
    "\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
    "\n",
    "        if self.output_attention:\n",
    "            return V.contiguous(), A\n",
    "        else:\n",
    "            return V.contiguous(), None\n",
    "\n",
    "\n",
    "class ProbAttention(nn.Module):\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
    "        super(ProbAttention, self).__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.output_attention = output_attention\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def _prob_QK(self, Q, K, sample_k, n_top):  # n_top: c*ln(L_q)\n",
    "        # Q [B, H, L, D]\n",
    "        B, H, L_K, E = K.shape\n",
    "        _, _, L_Q, _ = Q.shape\n",
    "\n",
    "        # calculate the sampled Q_K\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
    "        # real U = U_part(factor*ln(L_k))*L_q\n",
    "        index_sample = torch.randint(L_K, (L_Q, sample_k))\n",
    "        K_sample = K_expand[:, :, torch.arange(\n",
    "            L_Q).unsqueeze(1), index_sample, :]\n",
    "        Q_K_sample = torch.matmul(\n",
    "            Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze()\n",
    "\n",
    "        # find the Top_k query with sparisty measurement\n",
    "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
    "        M_top = M.topk(n_top, sorted=False)[1]\n",
    "\n",
    "        # use the reduced Q to calculate Q_K\n",
    "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
    "                   torch.arange(H)[None, :, None],\n",
    "                   M_top, :]  # factor*ln(L_q)\n",
    "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))  # factor*ln(L_q)*L_k\n",
    "\n",
    "        return Q_K, M_top\n",
    "\n",
    "    def _get_initial_context(self, V, L_Q):\n",
    "        B, H, L_V, D = V.shape\n",
    "        if not self.mask_flag:\n",
    "            # V_sum = V.sum(dim=-2)\n",
    "            V_sum = V.mean(dim=-2)\n",
    "            contex = V_sum.unsqueeze(-2).expand(B, H,\n",
    "                                                L_Q, V_sum.shape[-1]).clone()\n",
    "        else:  # use mask\n",
    "            # requires that L_Q == L_V, i.e. for self-attention only\n",
    "            assert (L_Q == L_V)\n",
    "            contex = V.cumsum(dim=-2)\n",
    "        return contex\n",
    "\n",
    "    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n",
    "        B, H, L_V, D = V.shape\n",
    "\n",
    "        if self.mask_flag:\n",
    "            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n",
    "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)  # nn.Softmax(dim=-1)(scores)\n",
    "\n",
    "        context_in[torch.arange(B)[:, None, None],\n",
    "        torch.arange(H)[None, :, None],\n",
    "        index, :] = torch.matmul(attn, V).type_as(context_in)\n",
    "        if self.output_attention:\n",
    "            attns = (torch.ones([B, H, L_V, L_V]) /\n",
    "                     L_V).type_as(attn).to(attn.device)\n",
    "            attns[torch.arange(B)[:, None, None], torch.arange(H)[\n",
    "                                                  None, :, None], index, :] = attn\n",
    "            return context_in, attns\n",
    "        else:\n",
    "            return context_in, None\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L_Q, H, D = queries.shape\n",
    "        _, L_K, _, _ = keys.shape\n",
    "\n",
    "        queries = queries.transpose(2, 1)\n",
    "        keys = keys.transpose(2, 1)\n",
    "        values = values.transpose(2, 1)\n",
    "\n",
    "        U_part = self.factor * \\\n",
    "                 np.ceil(np.log(L_K)).astype('int').item()  # c*ln(L_k)\n",
    "        u = self.factor * \\\n",
    "            np.ceil(np.log(L_Q)).astype('int').item()  # c*ln(L_q)\n",
    "\n",
    "        U_part = U_part if U_part < L_K else L_K\n",
    "        u = u if u < L_Q else L_Q\n",
    "\n",
    "        scores_top, index = self._prob_QK(\n",
    "            queries, keys, sample_k=U_part, n_top=u)\n",
    "\n",
    "        # add scale factor\n",
    "        scale = self.scale or 1. / sqrt(D)\n",
    "        if scale is not None:\n",
    "            scores_top = scores_top * scale\n",
    "        # get the context\n",
    "        context = self._get_initial_context(values, L_Q)\n",
    "        # update the context with selected top_k queries\n",
    "        context, attn = self._update_context(\n",
    "            context, values, scores_top, index, L_Q, attn_mask)\n",
    "\n",
    "        return context.contiguous(), attn\n",
    "\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "\n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "\n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "\n",
    "        out, attn = self.inner_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            attn_mask,\n",
    "            tau=tau,\n",
    "            delta=delta\n",
    "        )\n",
    "        out = out.view(B, L, -1)\n",
    "\n",
    "        return self.out_projection(out), attn\n",
    "\n",
    "\n",
    "class ReformerLayer(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
    "                 d_values=None, causal=False, bucket_size=4, n_hashes=4):\n",
    "        super().__init__()\n",
    "        self.bucket_size = bucket_size\n",
    "        self.attn = LSHSelfAttention(\n",
    "            dim=d_model,\n",
    "            heads=n_heads,\n",
    "            bucket_size=bucket_size,\n",
    "            n_hashes=n_hashes,\n",
    "            causal=causal\n",
    "        )\n",
    "\n",
    "    def fit_length(self, queries):\n",
    "        # inside reformer: assert N % (bucket_size * 2) == 0\n",
    "        B, N, C = queries.shape\n",
    "        if N % (self.bucket_size * 2) == 0:\n",
    "            return queries\n",
    "        else:\n",
    "            # fill the time series\n",
    "            fill_len = (self.bucket_size * 2) - (N % (self.bucket_size * 2))\n",
    "            return torch.cat([queries, torch.zeros([B, fill_len, C]).to(queries.device)], dim=1)\n",
    "\n",
    "    def forward(self, queries, keys, values, attn_mask, tau, delta):\n",
    "        # in Reformer: defalut queries=keys\n",
    "        B, N, C = queries.shape\n",
    "        queries = self.attn(self.fit_length(queries))[:, :N, :]\n",
    "        return queries, None\n",
    "\n",
    "\n",
    "class TwoStageAttentionLayer(nn.Module):\n",
    "    '''\n",
    "    The Two Stage Attention (TSA) Layer\n",
    "    input/output shape: [batch_size, Data_dim(D), Seg_num(L), d_model]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, configs,\n",
    "                 seg_num, factor, d_model, n_heads, d_ff=None, dropout=0.1):\n",
    "        super(TwoStageAttentionLayer, self).__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.time_attention = AttentionLayer(FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                                           output_attention=configs.output_attention), d_model, n_heads)\n",
    "        self.dim_sender = AttentionLayer(FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                                       output_attention=configs.output_attention), d_model, n_heads)\n",
    "        self.dim_receiver = AttentionLayer(FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                                         output_attention=configs.output_attention), d_model, n_heads)\n",
    "        self.router = nn.Parameter(torch.randn(seg_num, factor, d_model))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.norm4 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.MLP1 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "        self.MLP2 = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                  nn.GELU(),\n",
    "                                  nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x, attn_mask=None, tau=None, delta=None):\n",
    "        # Cross Time Stage: Directly apply MSA to each dimension\n",
    "        batch = x.shape[0]\n",
    "        time_in = rearrange(x, 'b ts_d seg_num d_model -> (b ts_d) seg_num d_model')\n",
    "        time_enc, attn = self.time_attention(\n",
    "            time_in, time_in, time_in, attn_mask=None, tau=None, delta=None\n",
    "        )\n",
    "        dim_in = time_in + self.dropout(time_enc)\n",
    "        dim_in = self.norm1(dim_in)\n",
    "        dim_in = dim_in + self.dropout(self.MLP1(dim_in))\n",
    "        dim_in = self.norm2(dim_in)\n",
    "\n",
    "        # Cross Dimension Stage: use a small set of learnable vectors to aggregate and distribute messages to build the D-to-D connection\n",
    "        dim_send = rearrange(dim_in, '(b ts_d) seg_num d_model -> (b seg_num) ts_d d_model', b=batch)\n",
    "        batch_router = repeat(self.router, 'seg_num factor d_model -> (repeat seg_num) factor d_model', repeat=batch)\n",
    "        dim_buffer, attn = self.dim_sender(batch_router, dim_send, dim_send, attn_mask=None, tau=None, delta=None)\n",
    "        dim_receive, attn = self.dim_receiver(dim_send, dim_buffer, dim_buffer, attn_mask=None, tau=None, delta=None)\n",
    "        dim_enc = dim_send + self.dropout(dim_receive)\n",
    "        dim_enc = self.norm3(dim_enc)\n",
    "        dim_enc = dim_enc + self.dropout(self.MLP2(dim_enc))\n",
    "        dim_enc = self.norm4(dim_enc)\n",
    "\n",
    "        final_out = rearrange(dim_enc, '(b seg_num) ts_d d_model -> b ts_d seg_num d_model', b=batch)\n",
    "\n",
    "        return final_out\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float()\n",
    "                    * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(\n",
    "            self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6,\n",
    "                    'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(\n",
    "                x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class DataEmbedding_inverted(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_inverted, self).__init__()\n",
    "        self.value_embedding = nn.Linear(c_in, d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x: [Batch Variate Time]\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(torch.cat([x, x_mark.permute(0, 2, 1)], 1))\n",
    "        # x: [Batch Variate d_model]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class DataEmbedding_wo_pos(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding_wo_pos, self).__init__()\n",
    "\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
    "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
    "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x)\n",
    "        else:\n",
    "            x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, patch_len, stride, padding, dropout):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch_layer = nn.ReplicationPad1d((0, padding))\n",
    "\n",
    "        # Backbone, Input encoding: projection of feature vectors onto a d-dim vector space\n",
    "        self.value_embedding = nn.Linear(patch_len, d_model, bias=False)\n",
    "\n",
    "        # Positional embedding\n",
    "        self.position_embedding = PositionalEmbedding(d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do patching\n",
    "        n_vars = x.shape[1]\n",
    "        x = self.padding_patch_layer(x)\n",
    "        x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
    "        x = torch.reshape(x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n",
    "        # Input encoding\n",
    "        x = self.value_embedding(x) + self.position_embedding(x)\n",
    "        return self.dropout(x), n_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.650Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Transformer_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Vanilla Transformer\n",
    "    with O(L^2) complexity\n",
    "    Paper link: https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,seq_len,pred_len,enc_in, num_experts=2, k=2):\n",
    "        super(Transformer_Model, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        e_layers = 3\n",
    "        n_heads = 8\n",
    "        d_model = 64\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False), d_model, n_heads),\n",
    "                    d_model) for l in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.dense_feature = nn.Linear(d_model,1)\n",
    "        # self.dense_feature = nn.Linear(d_model,80)\n",
    "        \n",
    "        self.embedding = Channel_Embedding_ablation(enc_in, out_channels=enc_in, num_experts=num_experts, k=k)\n",
    "\n",
    "\n",
    "    def forecast(self, x_enc):\n",
    "        # Embedding\n",
    "        x_enc = self.enc_embedding(x_enc, None)      # torch.Size([128, 50, 32])\n",
    "        enc_out, attns = self.encoder(x_enc, attn_mask=None)   # torch.Size([128, 50, 32])\n",
    "        \n",
    "        enc_out = self.dense_feature(enc_out)\n",
    "        return enc_out\n",
    "\n",
    "\n",
    "    def forward(self, x_enc):\n",
    "        B, _, _ = x_enc.shape\n",
    "        x = x_enc.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        x_enc = x.transpose(1, 2)  # B,M,L,D\n",
    "\n",
    "        \n",
    "        dec_out = self.forecast(x_enc)\n",
    "        \n",
    "        return dec_out[:, -self.pred_len:, :].squeeze(-1)  # [B, L, D]\n",
    "        # return dec_out[:, -self.pred_len:, :].squeeze(1)  # [B, L, D]\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,50,15))        # [B, L, D]\n",
    "#     model = Transformer_Model(seq_len=50,pred_len=1,enc_in=15)\n",
    "#     out = model(x)\n",
    "#     print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.650Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "class DLinear_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper link: https://arxiv.org/pdf/2205.13504.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,seq_len, pred_len, enc_in,decompsition_kernel_size=3, individual=False, num_experts=2, k=2):\n",
    "        super(DLinear_Model, self).__init__()\n",
    "        self.seq_len = seq_len          # 输入序列长度\n",
    "        self.pred_len = pred_len        # 输出序列长度\n",
    "        # Series decomposition block from Autoformer\n",
    "        self.decompsition = series_decomp(decompsition_kernel_size)     # 使用平均池化达到切分季节和趋势的目的\n",
    "        self.individual = individual        # True代表通道独立性，反之不使用通道独立性\n",
    "        self.channels = enc_in            # 选择通道个数\n",
    "\n",
    "        # 使用通道独立性，对每一个通道都使用不同的Linear进行预测，然后将预测结果统一\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = nn.ModuleList()\n",
    "            self.Linear_Trend = nn.ModuleList()\n",
    "\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Seasonal.append(\n",
    "                    nn.Linear(self.seq_len, self.pred_len))\n",
    "                self.Linear_Trend.append(\n",
    "                    nn.Linear(self.seq_len, self.pred_len))\n",
    "\n",
    "                self.Linear_Seasonal[i].weight = nn.Parameter(\n",
    "                    (1 / self.seq_len) * torch.ones([self.pred_len, self.seq_len]))\n",
    "                self.Linear_Trend[i].weight = nn.Parameter(\n",
    "                    (1 / self.seq_len) * torch.ones([self.pred_len, self.seq_len]))\n",
    "\n",
    "        # 不使用通道独立性，考虑到了通道之间的关系\n",
    "        else:\n",
    "            self.Linear_Seasonal = nn.Linear(self.seq_len, self.pred_len)\n",
    "            self.Linear_Trend = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "            self.Linear_Seasonal.weight = nn.Parameter(\n",
    "                (1 / self.seq_len) * torch.ones([self.pred_len, self.seq_len]))\n",
    "            self.Linear_Trend.weight = nn.Parameter(\n",
    "                (1 / self.seq_len) * torch.ones([self.pred_len, self.seq_len]))\n",
    "\n",
    "        self.dense_feature = nn.Linear(enc_in,1)\n",
    "        # self.dense_feature = nn.Linear(enc_in,80)\n",
    "        \n",
    "        self.dense_time = nn.Linear(self.seq_len,pred_len)\n",
    "\n",
    "\n",
    "        self.embedding = Channel_Embedding_ablation(enc_in, out_channels=enc_in, num_experts=num_experts, k=k)\n",
    "\n",
    "\n",
    "\n",
    "    def encoder(self, x):\n",
    "        seasonal_init, trend_init = self.decompsition(x)        # x: B, L(seq_len), D(多变量个数)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0, 2, 1), trend_init.permute(0, 2, 1)     # B, D, L\n",
    "\n",
    "        if self.individual:\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0), seasonal_init.size(1), self.pred_len],\n",
    "                                          dtype=seasonal_init.dtype).to(seasonal_init.device)       # B, D, pred_len\n",
    "            trend_output = torch.zeros([trend_init.size(0), trend_init.size(1), self.pred_len],\n",
    "                                       dtype=trend_init.dtype).to(trend_init.device)                # B, D, pred_len\n",
    "            for i in range(self.channels):\n",
    "                seasonal_output[:, i, :] = self.Linear_Seasonal[i](\n",
    "                    seasonal_init[:, i, :])\n",
    "                trend_output[:, i, :] = self.Linear_Trend[i](\n",
    "                    trend_init[:, i, :])\n",
    "        else:\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, _, _ = x.shape\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1, 2)  # B,M,L,D\n",
    "\n",
    "        \n",
    "        dec_out = self.encoder(x)\n",
    "        # print(dec_out.shape)\n",
    "\n",
    "        dec_out = self.dense_feature(dec_out).squeeze(-1)\n",
    "        # print(dec_out.shape)\n",
    "        # out = self.dense_time(dec_out)\n",
    "        # return out  # [B, L, D]\n",
    "\n",
    "        return dec_out[:, -self.pred_len:]  # [B, L, D]\n",
    "\n",
    "\n",
    "        # dec_out = self.dense_feature(dec_out)\n",
    "        # return dec_out[:, -self.pred_len:,:].squeeze(1)  # [B, L, D]\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # [B, L, D]\n",
    "#     model = DLinear_Model(seq_len=32,pred_len=1,enc_in=15,individual=False)\n",
    "#     out = model(x)\n",
    "#     print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.650Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        其实这就是一个裁剪的模块，裁剪多出来的padding\n",
    "        \"\"\"\n",
    "        # print(x,x.shape)\n",
    "        # print(x[:, :, :-self.chomp_size].contiguous(),x[:, :, :-self.chomp_size].contiguous().shape)\n",
    "        # print('以进行裁剪')\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        \"\"\"\n",
    "        相当于一个Residual block\n",
    "\n",
    "        :param n_inputs: int, 输入通道数\n",
    "        :param n_outputs: int, 输出通道数\n",
    "        :param kernel_size: int, 卷积核尺寸\n",
    "        :param stride: int, 步长，一般为1\n",
    "        :param dilation: int, 膨胀系数\n",
    "        :param padding: int, 填充系数\n",
    "        :param dropout: float, dropout比率\n",
    "        \"\"\"\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        # 经过conv1，输出的size其实是(Batch, input_channel, seq_len + padding)\n",
    "        self.chomp1 = Chomp1d(padding)  # 裁剪掉多出来的padding部分，维持输出时间步为seq_len\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)  # 裁剪掉多出来的padding部分，维持输出时间步为seq_len\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        参数初始化\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # print(self.conv1.weight.shape)\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TCN_Model(nn.Module):\n",
    "    def __init__(self, num_inputs,seq_len, num_channels,pred_len, kernel_size=2, dropout=0.2,num_experts=2,k=2):\n",
    "        \"\"\"\n",
    "        TCN，目前paper给出的TCN结构很好的支持每个时刻为一个数的情况，即sequence结构，\n",
    "        对于每个时刻为一个向量这种一维结构，勉强可以把向量拆成若干该时刻的输入通道，\n",
    "        对于每个时刻为一个矩阵或更高维图像的情况，就不太好办。\n",
    "\n",
    "        :param num_inputs: int， 输入通道数\n",
    "        :param num_channels: list，每层的hidden_channel数，例如[25,25,25,25]表示有4个隐层，每层hidden_channel数为25，也就代表有25个卷积核在这次卷积中执行\n",
    "        :param kernel_size: int, 卷积核尺寸，只需要定义卷积核长度\n",
    "        :param dropout: float, drop_out比率\n",
    "        \"\"\"\n",
    "        super(TCN_Model, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i  # 膨胀系数：1，2，4，8……\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i - 1]  # 确定每一层的输入通道数\n",
    "            out_channels = num_channels[i]  # 确定每一层的输出通道数\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n",
    "                                     dilation=dilation_size,                        # 膨胀卷积\n",
    "                                     padding=(kernel_size - 1) * dilation_size,     # 因果卷积\n",
    "                                     dropout=dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.dense_pred = nn.Linear(seq_len,pred_len)\n",
    "        self.dense_feature = nn.Linear(num_channels[-1],1)\n",
    "        \n",
    "        # self.dense_feature = nn.Linear(num_channels[-1],80)\n",
    "    \n",
    "        self.embedding = Channel_Embedding_ablation(num_inputs, out_channels=num_inputs, num_experts=num_experts, k=k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入x的结构不同于RNN，一般RNN的size为(Batch, seq_len, channels)或者(seq_len, Batch, channels)，\n",
    "        这里把seq_len放在channels后面，把所有时间步的数据拼起来，当做Conv1d的输入尺寸，实现卷积跨时间步的操作，\n",
    "        很巧妙的设计。\n",
    "\n",
    "        为什么输入和输出数据结构是这样的\n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return: size of (Batch, output_channel, seq_len)\n",
    "        \"\"\"\n",
    "        B, _, _ = x.shape\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1, 2)  # B,M,L,D\n",
    "\n",
    "        \n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.network(x)\n",
    "        x = self.dense_feature(x.permute(0,2,1)).squeeze(-1)\n",
    "        x = self.dense_pred(x)\n",
    "\n",
    "        # x = self.dense_feature(x.permute(0,2,1)).permute(0,2,1)\n",
    "        # x = self.dense_pred(x).squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     x = torch.randn((128,50,15))        # [B, L, D]\n",
    "#     model = TemporalConvNet(num_inputs=15, num_channels=[10,5], kernel_size=2,seq_len=50,pred_len=1)\n",
    "#     out = model(x)\n",
    "#     print(out.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModernTCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.650Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, P=8, S=4, D=2048):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=D,\n",
    "            kernel_size=P,\n",
    "            stride=S\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, M, L]\n",
    "        B = x.shape[0]\n",
    "        x = x.unsqueeze(2)  # 新增一个维度作为通道数 [B, M, L] -> [B, M, 1, L]\n",
    "        x = rearrange(x, 'b m r l -> (b m) r l')  # [B, M, 1, L] -> [B*M, 1, L]\n",
    "        x_pad = F.pad(\n",
    "            x,\n",
    "            pad=(0, self.P - self.S),       # 第一个维度不填充，填充第二个维度\n",
    "            mode='replicate'                # 复制边缘元素的值进行填充\n",
    "        )  # [B*M, 1, L] -> [B*M, 1, L+P-S]\n",
    "\n",
    "        x_emb = self.conv(x_pad)  # [B*M, 1, L+P-S] -> [B*M, D, N]\n",
    "        x_emb = rearrange(x_emb, '(b m) d n -> b m d n', b=B)  # [B*M, D, N] -> [B, M, D, N]\n",
    "\n",
    "        return x_emb  # x_emb: [B, M, D, N]\n",
    "\n",
    "\n",
    "class ConvFFN(nn.Module):\n",
    "    def __init__(self, M, D, r, one=True):  # one is True: ConvFFN1, one is False: ConvFFN2\n",
    "        super(ConvFFN, self).__init__()\n",
    "        groups_num = M if one else D\n",
    "        self.pw_con1 = nn.Conv1d(\n",
    "            in_channels=M * D,\n",
    "            out_channels=r * M * D,\n",
    "            kernel_size=1,\n",
    "            groups=groups_num\n",
    "        )\n",
    "        self.pw_con2 = nn.Conv1d(\n",
    "            in_channels=r * M * D,\n",
    "            out_channels=M * D,\n",
    "            kernel_size=1,\n",
    "            groups=groups_num\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, M*D, N]\n",
    "        x = self.pw_con2(F.gelu(self.pw_con1(x)))\n",
    "        return x  # x: [B, M*D, N]\n",
    "\n",
    "\n",
    "class ModernTCNBlock(nn.Module):\n",
    "    def __init__(self, M, D, kernel_size, r):\n",
    "        super(ModernTCNBlock, self).__init__()\n",
    "        # 深度分离卷积负责捕获时域关系(输出的通道数并没有改变)\n",
    "        # 深度卷积的分组数等于输入的通道数，且输入通道等于输出通道\n",
    "        self.dw_conv = nn.Conv1d(\n",
    "            in_channels=M * D,\n",
    "            out_channels=M * D,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=M * D,\n",
    "            padding='same'\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(M * D)\n",
    "        self.conv_ffn1 = ConvFFN(M, D, r, one=True)    # 分为M个组\n",
    "        self.conv_ffn2 = ConvFFN(M, D, r, one=False)   # 分为D个组\n",
    "\n",
    "    def forward(self, x_emb):\n",
    "        # x_emb: [B, M, D, N]\n",
    "        D = x_emb.shape[-2]\n",
    "        x = rearrange(x_emb, 'b m d n -> b (m d) n')  # [B, M, D, N] -> [B, M*D, N]\n",
    "        x = self.dw_conv(x)  # [B, M*D, N] -> [B, M*D, N]\n",
    "        x = self.bn(x)  # [B, M*D, N] -> [B, M*D, N]\n",
    "        x = self.conv_ffn1(x)  # [B, M*D, N] -> [B, M*D, N]\n",
    "\n",
    "        x = rearrange(x, 'b (m d) n -> b m d n', d=D)  # [B, M*D, N] -> [B, M, D, N]\n",
    "        x = x.permute(0, 2, 1, 3)  # [B, M, D, N] -> [B, D, M, N]\n",
    "        x = rearrange(x, 'b d m n -> b (d m) n')  # [B, D, M, N] -> [B, D*M, N]\n",
    "\n",
    "        x = self.conv_ffn2(x)  # [B, D*M, N] -> [B, D*M, N]\n",
    "\n",
    "        x = rearrange(x, 'b (d m) n -> b d m n', d=D)  # [B, D*M, N] -> [B, D, M, N]\n",
    "        x = x.permute(0, 2, 1, 3)  # [B, D, M, N] -> [B, M, D, N]\n",
    "\n",
    "        out = x + x_emb\n",
    "        return out  # out: [B, M, D, N]\n",
    "\n",
    "\n",
    "class ModernTCN(nn.Module):\n",
    "    def __init__(self, M, L, T, D=2048, P=8, S=4, kernel_size=51, r=1, num_layers=2,num_experts=2,k=2):\n",
    "        super(ModernTCN, self).__init__()\n",
    "        # 深度分离卷积负责捕获时域关系\n",
    "        self.num_layers = num_layers\n",
    "        N = L // S\n",
    "        self.embed_layer = Embedding(P, S, D)\n",
    "        self.backbone = nn.ModuleList([ModernTCNBlock(M, D, kernel_size, r) for _ in range(num_layers)])\n",
    "        self.head = nn.Linear(D*N, T)\n",
    "        self.dense_feature = nn.Linear(M,1)\n",
    "\n",
    "        # self.dense_feature = nn.Linear(M,80)\n",
    "\n",
    "        self.embedding = Channel_Embedding_ablation(M, out_channels=M, num_experts=num_experts, k=k)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B, _, _ = x.shape\n",
    "        # x = x.permute(0, 2, 1)\n",
    "        # x = self.embedding(x)\n",
    "        # x = x.transpose(1, 2)  # B,M,L,D\n",
    "\n",
    "\n",
    "        x = x.permute(0,2,1)        # [B, L, M] -> [B, M, L]\n",
    "        x_emb = self.embed_layer(x)  # [B, M, L] -> [B, M, D, N]\n",
    "        # print(x_emb.shape)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x_emb = self.backbone[i](x_emb)  # [B, M, D, N] -> [B, M, D, N]\n",
    "\n",
    "        # Flatten\n",
    "        z = rearrange(x_emb, 'b m d n -> b m (d n)')  # [B, M, D, N] -> [B, M, D*N]\n",
    "        pred = self.dense_feature(z.permute(0,2,1))\n",
    "        pred = self.head(pred.squeeze(-1))\n",
    "\n",
    "        # pred = self.dense_feature(z.permute(0,2,1)).permute(0,2,1)\n",
    "        # pred = self.head(pred).squeeze(-1)\n",
    "        return pred  # out: [B, M, T]\n",
    "\n",
    "\n",
    "# B：batch size\n",
    "# M：多变量序列的变量数\n",
    "# L：过去序列的长度(时间窗口大小)\n",
    "# T: 预测序列的长度\n",
    "# N: 分Patch后Patch的个数\n",
    "# D：每个变量的通道数（可能是代表着一个变量有多个特征，而每个特征就是一个通道），那么M个变量，也就有M*D个通道，也就是DWConv中的通道数\n",
    "# P：kernel size of embedding layer\n",
    "# S：stride of embedding layer\n",
    "\n",
    "\n",
    "# past_series = torch.rand(2, 4, 96)      # B, M, L\n",
    "# model = ModernTCN(4, 96, 192)           # 利用时间窗口96预测192，长时间预测\n",
    "# pred_series = model(past_series)\n",
    "# print(pred_series.shape)   # torch.Size([2, 4, 192])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     x = torch.randn((128,32,15))        # [B, L, D]\n",
    "#     model = ModernTCN(M=15,L=32,T=1,D=64)\n",
    "#     out = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Att-CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-21T02:32:10.651Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Att_CNN_LSTM(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,hidden_size,seq_len,kernel_size,dilation_size,pred_len,num_experts=2,k=2):\n",
    "        super(Att_CNN_LSTM, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,\n",
    "                                           stride=1, padding=(kernel_size - 1) * dilation_size, dilation=dilation_size)\n",
    "        self.conv = nn.Sequential(\n",
    "            # nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3),\n",
    "            self.conv1,\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        )\n",
    "        self.dense1 = nn.Linear(seq_len, seq_len)\n",
    "        self.lstm = nn.LSTM(input_size=out_channels+in_channels, hidden_size=hidden_size,\n",
    "                            num_layers=2, batch_first=True)\n",
    "        self.dense2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size,num_heads=4,batch_first=True,\n",
    "                                               dropout=0.2)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        # self.fc = nn.Linear(hidden_size, 80)\n",
    "\n",
    "        self.fc_time = nn.Linear(seq_len,pred_len)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "        self.embedding = Channel_Embedding_ablation(in_channels, out_channels=in_channels, num_experts=num_experts, k=k)\n",
    "\n",
    "\n",
    "    def forward(self, emb_x):\n",
    "        '''\n",
    "        x:(batch,in_channel,seq_len)        作为conv1d输入\n",
    "          (batch,seq_len-kernel_size+1,out_channel)     # 作为LSTM的输入\n",
    "        '''\n",
    "        B, _, _ = emb_x.shape\n",
    "        x = emb_x.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        emb_x = x.transpose(1, 2)  # B,M,L,D\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        emb_x = emb_x.permute(0,2,1)\n",
    "        conv_x = self.conv(emb_x)            # (batch,out_channel,seq_len-kernel_size*2+2)       # 因为有池化层的kernel_size\n",
    "        conv_x = self.dense1(conv_x)\n",
    "        x = torch.cat((conv_x,emb_x),dim=1)\n",
    "        x = x.permute(0, 2, 1)      # (batch,seq_len-kernel_size*2+2,out_channel)\n",
    "        x, _ = self.lstm(x)         # (batch,seq_len-kernel_size*2+2,hidden_size)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x, _ = self.attention(x,x,x)\n",
    "        x = self.fc(x).squeeze(-1)\n",
    "        x = self.fc_time(x)\n",
    "\n",
    "        # x = self.fc(x).permute(0,2,1)\n",
    "        # x = self.fc_time(x).squeeze(-1)   \n",
    "        return x\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     x = torch.randn((128,50,15))        # [B, L, D]\n",
    "#     model = Att_CNN_LSTM(in_channels=15,out_channels=16,hidden_size=64,seq_len=50,kernel_size=2,dilation_size=1,pred_len=1)\n",
    "#     out = model(x)\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T05:56:53.526512Z",
     "iopub.status.busy": "2025-12-08T05:56:53.526223Z",
     "iopub.status.idle": "2025-12-08T05:56:57.039796Z",
     "shell.execute_reply": "2025-12-08T05:56:57.038982Z",
     "shell.execute_reply.started": "2025-12-08T05:56:53.526488Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This examples is not intended to be optimized. Its purpose is to show how to handle\n",
    "big datasets with multiple sequences. The accuracy should be around 10%.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "import torch.sparse\n",
    "\n",
    "\n",
    "def apply_permutation(tensor, permutation, dim=1):\n",
    "    # type: (Tensor, Tensor, int) -> Tensor\n",
    "    return tensor.index_select(dim, permutation)\n",
    "\n",
    "\n",
    "class Reservoir(nn.Module):\n",
    "\n",
    "    def __init__(self, mode, input_size, hidden_size, num_layers, leaking_rate,\n",
    "                 spectral_radius, w_ih_scale,\n",
    "                 density, bias=True, batch_first=False):\n",
    "        super(Reservoir, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.w_ih_scale = w_ih_scale\n",
    "        self.density = density\n",
    "        self.bias = bias\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        self._all_weights = []\n",
    "        for layer in range(num_layers):\n",
    "            layer_input_size = input_size if layer == 0 else hidden_size\n",
    "\n",
    "            w_ih = nn.Parameter(torch.Tensor(hidden_size, layer_input_size))\n",
    "            w_hh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "            b_ih = nn.Parameter(torch.Tensor(hidden_size))\n",
    "            layer_params = (w_ih, w_hh, b_ih)\n",
    "\n",
    "            param_names = ['weight_ih_l{}{}', 'weight_hh_l{}{}']\n",
    "            if bias:\n",
    "                param_names += ['bias_ih_l{}{}']\n",
    "            param_names = [x.format(layer, '') for x in param_names]\n",
    "\n",
    "            for name, param in zip(param_names, layer_params):\n",
    "                setattr(self, name, param)\n",
    "            self._all_weights.append(param_names)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def _apply(self, fn):\n",
    "        ret = super(Reservoir, self)._apply(fn)\n",
    "        return ret\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        weight_dict = self.state_dict()\n",
    "        for key, value in weight_dict.items():\n",
    "            if key == 'weight_ih_l0':\n",
    "                nn.init.uniform_(value, -1, 1)\n",
    "                value *= self.w_ih_scale[1:]\n",
    "            elif re.fullmatch('weight_ih_l[^0]*', key):\n",
    "                nn.init.uniform_(value, -1, 1)\n",
    "            elif re.fullmatch('bias_ih_l[0-9]*', key):\n",
    "                nn.init.uniform_(value, -1, 1)\n",
    "                value *= self.w_ih_scale[0]\n",
    "            elif re.fullmatch('weight_hh_l[0-9]*', key):\n",
    "                w_hh = torch.Tensor(self.hidden_size * self.hidden_size)\n",
    "                w_hh.uniform_(-1, 1)\n",
    "                if self.density < 1:\n",
    "                    zero_weights = torch.randperm(\n",
    "                        int(self.hidden_size * self.hidden_size))\n",
    "                    zero_weights = zero_weights[\n",
    "                                   :int(\n",
    "                                       self.hidden_size * self.hidden_size * (\n",
    "                                                   1 - self.density))]\n",
    "                    w_hh[zero_weights] = 0\n",
    "                w_hh = w_hh.view(self.hidden_size, self.hidden_size)\n",
    "                abs_eigs = torch.abs(torch.linalg.eigvals(w_hh))\n",
    "                weight_dict[key] = w_hh * (self.spectral_radius / torch.max(abs_eigs))\n",
    "\n",
    "        self.load_state_dict(weight_dict)\n",
    "\n",
    "    def check_input(self, input, batch_sizes):\n",
    "        # type: (Tensor, Optional[Tensor]) -> None\n",
    "        expected_input_dim = 2 if batch_sizes is not None else 3\n",
    "        if input.dim() != expected_input_dim:\n",
    "            raise RuntimeError(\n",
    "                'input must have {} dimensions, got {}'.format(\n",
    "                    expected_input_dim, input.dim()))\n",
    "        if self.input_size != input.size(-1):\n",
    "            raise RuntimeError(\n",
    "                'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n",
    "                    self.input_size, input.size(-1)))\n",
    "\n",
    "    def get_expected_hidden_size(self, input, batch_sizes):\n",
    "        # type: (Tensor, Optional[Tensor]) -> Tuple[int, int, int]\n",
    "        if batch_sizes is not None:\n",
    "            mini_batch = batch_sizes[0]\n",
    "            mini_batch = int(mini_batch)\n",
    "        else:\n",
    "            mini_batch = input.size(0) if self.batch_first else input.size(1)\n",
    "        expected_hidden_size = (self.num_layers, mini_batch, self.hidden_size)\n",
    "        return expected_hidden_size\n",
    "\n",
    "    def check_hidden_size(self, hx, expected_hidden_size, msg='Expected hidden size {}, got {}'):\n",
    "        # type: (Tensor, Tuple[int, int, int], str) -> None\n",
    "        if hx.size() != expected_hidden_size:\n",
    "            raise RuntimeError(msg.format(expected_hidden_size, tuple(hx.size())))\n",
    "\n",
    "    def check_forward_args(self, input, hidden, batch_sizes):\n",
    "        # type: (Tensor, Tensor, Optional[Tensor]) -> None\n",
    "        self.check_input(input, batch_sizes)\n",
    "        expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)\n",
    "\n",
    "        self.check_hidden_size(hidden, expected_hidden_size)\n",
    "\n",
    "    def permute_hidden(self, hx, permutation):\n",
    "        # type: (Tensor, Optional[Tensor]) -> Tensor\n",
    "        if permutation is None:\n",
    "            return hx\n",
    "        return apply_permutation(hx, permutation)\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        is_packed = isinstance(input, PackedSequence)\n",
    "        if is_packed:\n",
    "            input, batch_sizes, sorted_indices, unsorted_indices = input\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = input.size(0) if self.batch_first else input.size(1)\n",
    "            sorted_indices = None\n",
    "            unsorted_indices = None\n",
    "\n",
    "        if hx is None:\n",
    "            hx = input.new_zeros(self.num_layers, max_batch_size,\n",
    "                                 self.hidden_size, requires_grad=False)\n",
    "        else:\n",
    "            # Each batch of the hidden state should match the input sequence that\n",
    "            # the user believes he/she is passing in.\n",
    "            hx = self.permute_hidden(hx, sorted_indices)\n",
    "\n",
    "        flat_weight = None\n",
    "\n",
    "        self.check_forward_args(input, hx, batch_sizes)\n",
    "        func = AutogradReservoir(\n",
    "            self.mode,\n",
    "            self.input_size,\n",
    "            self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=self.batch_first,\n",
    "            train=self.training,\n",
    "            variable_length=is_packed,\n",
    "            flat_weight=flat_weight,\n",
    "            leaking_rate=self.leaking_rate\n",
    "        )\n",
    "        output, hidden = func(input, self.all_weights, hx, batch_sizes)\n",
    "        if is_packed:\n",
    "            output = PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)\n",
    "        return output, self.permute_hidden(hidden, unsorted_indices)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = '({input_size}, {hidden_size}'\n",
    "        if self.num_layers != 1:\n",
    "            s += ', num_layers={num_layers}'\n",
    "        if self.bias is not True:\n",
    "            s += ', bias={bias}'\n",
    "        if self.batch_first is not False:\n",
    "            s += ', batch_first={batch_first}'\n",
    "        s += ')'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        super(Reservoir, self).__setstate__(d)\n",
    "        self.__dict__.setdefault('_data_ptrs', [])\n",
    "        if 'all_weights' in d:\n",
    "            self._all_weights = d['all_weights']\n",
    "        if isinstance(self._all_weights[0][0], str):\n",
    "            return\n",
    "        num_layers = self.num_layers\n",
    "        self._all_weights = []\n",
    "        for layer in range(num_layers):\n",
    "            weights = ['weight_ih_l{}{}', 'weight_hh_l{}{}', 'bias_ih_l{}{}']\n",
    "            weights = [x.format(layer) for x in weights]\n",
    "            if self.bias:\n",
    "                self._all_weights += [weights]\n",
    "            else:\n",
    "                self._all_weights += [weights[:2]]\n",
    "\n",
    "    @property\n",
    "    def all_weights(self):\n",
    "        return [[getattr(self, weight) for weight in weights] for weights in\n",
    "                self._all_weights]\n",
    "\n",
    "\n",
    "def AutogradReservoir(mode, input_size, hidden_size, num_layers=1,\n",
    "                      batch_first=False, train=True,\n",
    "                      batch_sizes=None, variable_length=False, flat_weight=None,\n",
    "                      leaking_rate=1):\n",
    "    if mode == 'RES_TANH':\n",
    "        cell = ResTanhCell\n",
    "    elif mode == 'RES_RELU':\n",
    "        cell = ResReLUCell\n",
    "    elif mode == 'RES_ID':\n",
    "        cell = ResIdCell\n",
    "\n",
    "    if variable_length:\n",
    "        layer = (VariableRecurrent(cell, leaking_rate),)\n",
    "    else:\n",
    "        layer = (Recurrent(cell, leaking_rate),)\n",
    "\n",
    "    func = StackedRNN(layer,\n",
    "                      num_layers,\n",
    "                      False,\n",
    "                      train=train)\n",
    "\n",
    "    def forward(input, weight, hidden, batch_sizes):\n",
    "        if batch_first and batch_sizes is None:\n",
    "            input = input.transpose(0, 1)\n",
    "\n",
    "        nexth, output = func(input, hidden, weight, batch_sizes)\n",
    "\n",
    "        if batch_first and not variable_length:\n",
    "            output = output.transpose(0, 1)\n",
    "\n",
    "        return output, nexth\n",
    "\n",
    "    return forward\n",
    "\n",
    "\n",
    "def Recurrent(inner, leaking_rate):\n",
    "    def forward(input, hidden, weight, batch_sizes):\n",
    "        output = []\n",
    "        steps = range(input.size(0))\n",
    "        for i in steps:\n",
    "            hidden = inner(input[i], hidden, leaking_rate, *weight)\n",
    "            # hack to handle LSTM\n",
    "            output.append(hidden[0] if isinstance(hidden, tuple) else hidden)\n",
    "\n",
    "        output = torch.cat(output, 0).view(input.size(0), *output[0].size())\n",
    "\n",
    "        return hidden, output\n",
    "\n",
    "    return forward\n",
    "\n",
    "\n",
    "def VariableRecurrent(inner, leaking_rate):\n",
    "    def forward(input, hidden, weight, batch_sizes):\n",
    "        output = []\n",
    "        input_offset = 0\n",
    "        last_batch_size = batch_sizes[0]\n",
    "        hiddens = []\n",
    "        flat_hidden = not isinstance(hidden, tuple)\n",
    "        if flat_hidden:\n",
    "            hidden = (hidden,)\n",
    "        for batch_size in batch_sizes:\n",
    "            step_input = input[input_offset:input_offset + batch_size]\n",
    "            input_offset += batch_size\n",
    "\n",
    "            dec = last_batch_size - batch_size\n",
    "            if dec > 0:\n",
    "                hiddens.append(tuple(h[-dec:] for h in hidden))\n",
    "                hidden = tuple(h[:-dec] for h in hidden)\n",
    "            last_batch_size = batch_size\n",
    "\n",
    "            if flat_hidden:\n",
    "                hidden = (inner(step_input, hidden[0], leaking_rate, *weight),)\n",
    "            else:\n",
    "                hidden = inner(step_input, hidden, leaking_rate, *weight)\n",
    "\n",
    "            output.append(hidden[0])\n",
    "        hiddens.append(hidden)\n",
    "        hiddens.reverse()\n",
    "\n",
    "        hidden = tuple(torch.cat(h, 0) for h in zip(*hiddens))\n",
    "        assert hidden[0].size(0) == batch_sizes[0]\n",
    "        if flat_hidden:\n",
    "            hidden = hidden[0]\n",
    "        output = torch.cat(output, 0)\n",
    "\n",
    "        return hidden, output\n",
    "\n",
    "    return forward\n",
    "\n",
    "\n",
    "def StackedRNN(inners, num_layers, lstm=False, train=True):\n",
    "    num_directions = len(inners)\n",
    "    total_layers = num_layers * num_directions\n",
    "\n",
    "    def forward(input, hidden, weight, batch_sizes):\n",
    "        assert (len(weight) == total_layers)\n",
    "        next_hidden = []\n",
    "        all_layers_output = []\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            all_output = []\n",
    "            for j, inner in enumerate(inners):\n",
    "                l = i * num_directions + j\n",
    "\n",
    "                hy, output = inner(input, hidden[l], weight[l], batch_sizes)\n",
    "                next_hidden.append(hy)\n",
    "                all_output.append(output)\n",
    "\n",
    "            input = torch.cat(all_output, input.dim() - 1)\n",
    "            all_layers_output.append(input)\n",
    "\n",
    "        all_layers_output = torch.cat(all_layers_output, -1)\n",
    "        next_hidden = torch.cat(next_hidden, 0).view(\n",
    "            total_layers, *next_hidden[0].size())\n",
    "\n",
    "        return next_hidden, all_layers_output\n",
    "\n",
    "    return forward\n",
    "\n",
    "\n",
    "def ResTanhCell(input, hidden, leaking_rate, w_ih, w_hh, b_ih=None):\n",
    "    hy_ = torch.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh))\n",
    "    hy = (1 - leaking_rate) * hidden + leaking_rate * hy_\n",
    "    return hy\n",
    "\n",
    "\n",
    "def ResReLUCell(input, hidden, leaking_rate, w_ih, w_hh, b_ih=None):\n",
    "    hy_ = F.relu(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh))\n",
    "    hy = (1 - leaking_rate) * hidden + leaking_rate * hy_\n",
    "    return hy\n",
    "\n",
    "\n",
    "def ResIdCell(input, hidden, leaking_rate, w_ih, w_hh, b_ih=None):\n",
    "    hy_ = F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh)\n",
    "    hy = (1 - leaking_rate) * hidden + leaking_rate * hy_\n",
    "    return hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T06:10:21.672328Z",
     "iopub.status.busy": "2025-12-08T06:10:21.671998Z",
     "iopub.status.idle": "2025-12-08T06:10:21.703704Z",
     "shell.execute_reply": "2025-12-08T06:10:21.702794Z",
     "shell.execute_reply.started": "2025-12-08T06:10:21.672304Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "def prepare_target(target, seq_lengths, washout, batch_first=False):\n",
    "    \"\"\" Preprocess target for offline training.\n",
    "\n",
    "    Args:\n",
    "        target (seq_len, batch, output_size): tensor containing\n",
    "            the features of the target sequence.\n",
    "        seq_lengths: list of lengths of each sequence in the batch.\n",
    "        washout: number of initial timesteps during which output of the\n",
    "            reservoir is not forwarded to the readout. One value per sample.\n",
    "        batch_first: If ``True``, then the input and output tensors are provided\n",
    "            as (batch, seq, feature). Default: ``False``\n",
    "\n",
    "    Returns:\n",
    "        tensor containing the features of the batch's sequences rolled out along\n",
    "        one axis, minus the washouts and the padded values.\n",
    "    \"\"\"\n",
    "\n",
    "    if batch_first:\n",
    "        target = target.transpose(0, 1)\n",
    "    n_sequences = target.size(1)\n",
    "    target_dim = target.size(2)\n",
    "    train_len = sum(torch.tensor(seq_lengths) - torch.tensor(washout)).item()\n",
    "\n",
    "    new_target = torch.zeros(train_len, target_dim, device=target.device)\n",
    "\n",
    "    idx = 0\n",
    "    for s in range(n_sequences):\n",
    "        batch_len = seq_lengths[s] - washout[s]\n",
    "        new_target[idx:idx + batch_len, :] = target[washout[s]:seq_lengths[s], s, :]\n",
    "        idx += batch_len\n",
    "\n",
    "    return new_target\n",
    "\n",
    "\n",
    "def washout_tensor(tensor, washout, seq_lengths, bidirectional=False, batch_first=False):\n",
    "    tensor = tensor.transpose(0, 1) if batch_first else tensor.clone()\n",
    "    if type(seq_lengths) == list:\n",
    "        seq_lengths = seq_lengths.copy()\n",
    "    if type(seq_lengths) == torch.Tensor:\n",
    "        seq_lengths = seq_lengths.clone()\n",
    "\n",
    "    for b in range(tensor.size(1)):\n",
    "        if washout[b] > 0:\n",
    "            tmp = tensor[washout[b]:seq_lengths[b], b].clone()\n",
    "            tensor[:seq_lengths[b] - washout[b], b] = tmp\n",
    "            tensor[seq_lengths[b] - washout[b]:, b] = 0\n",
    "            seq_lengths[b] -= washout[b]\n",
    "\n",
    "            if bidirectional:\n",
    "                tensor[seq_lengths[b] - washout[b]:, b] = 0\n",
    "                seq_lengths[b] -= washout[b]\n",
    "\n",
    "    if type(seq_lengths) == list:\n",
    "        max_len = max(seq_lengths)\n",
    "    else:\n",
    "        max_len = max(seq_lengths).item()\n",
    "\n",
    "    return tensor[:max_len], seq_lengths\n",
    "\n",
    "\n",
    "class ESN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,time_len=32, pred_len=1, num_layers=1,\n",
    "                 nonlinearity='tanh', batch_first=False, leaking_rate=1,\n",
    "                 spectral_radius=0.9, w_ih_scale=1, lambda_reg=0, density=1,\n",
    "                 w_io=False, readout_training='svd', output_steps='all'\n",
    "                ,num_experts=3,k=3\n",
    "                ):\n",
    "        super(ESN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        if nonlinearity == 'tanh':\n",
    "            mode = 'RES_TANH'\n",
    "        elif nonlinearity == 'relu':\n",
    "            mode = 'RES_RELU'\n",
    "        elif nonlinearity == 'id':\n",
    "            mode = 'RES_ID'\n",
    "        else:\n",
    "            raise ValueError(\"Unknown nonlinearity '{}'\".format(nonlinearity))\n",
    "        self.batch_first = batch_first\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.spectral_radius = spectral_radius\n",
    "        if type(w_ih_scale) != torch.Tensor:\n",
    "            self.w_ih_scale = torch.ones(input_size + 1)\n",
    "            self.w_ih_scale *= w_ih_scale\n",
    "        else:\n",
    "            self.w_ih_scale = w_ih_scale\n",
    "\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.density = density\n",
    "        self.w_io = w_io\n",
    "        if readout_training in {'gd', 'svd', 'cholesky', 'inv'}:\n",
    "            self.readout_training = readout_training\n",
    "        else:\n",
    "            raise ValueError(\"Unknown readout training algorithm '{}'\".format(\n",
    "                readout_training))\n",
    "\n",
    "        self.reservoir = Reservoir(mode, input_size, hidden_size, num_layers,\n",
    "                                   leaking_rate, spectral_radius,\n",
    "                                   self.w_ih_scale, density,\n",
    "                                   batch_first=batch_first)\n",
    "\n",
    "        if w_io:\n",
    "            self.readout = nn.Linear(input_size + hidden_size * num_layers,\n",
    "                                     output_size)\n",
    "        else:\n",
    "            self.readout = nn.Linear(hidden_size * num_layers, output_size)\n",
    "        if readout_training == 'offline':\n",
    "            self.readout.weight.requires_grad = False\n",
    "\n",
    "        if output_steps in {'all', 'mean', 'last'}:\n",
    "            self.output_steps = output_steps\n",
    "        else:\n",
    "            raise ValueError(\"Unknown task '{}'\".format(\n",
    "                output_steps))\n",
    "\n",
    "        self.XTX = None\n",
    "        self.XTy = None\n",
    "        self.X = None\n",
    "\n",
    "        self.dense_time = nn.Linear(time_len-int(0.2 * time_len),pred_len)\n",
    "\n",
    "\n",
    "        self.embedding = Channel_Embedding_ablation(input_size, out_channels=input_size, num_experts=num_experts, k=k)\n",
    "\n",
    "\n",
    "    def forward(self, input, h_0=None, target=None):\n",
    "        B, _, _ = input.shape\n",
    "        x = input.permute(0, 2, 1)\n",
    "        x = self.embedding(x)\n",
    "        input = x.transpose(1, 2)  # B,M,L,D\n",
    "        \n",
    "        input = input.permute(1,0,2)\n",
    "        washout = [int(0.2 * input.size(0))] * input.size(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            is_packed = isinstance(input, PackedSequence)\n",
    "\n",
    "            output, hidden = self.reservoir(input, h_0)\n",
    "            if is_packed:\n",
    "                output, seq_lengths = pad_packed_sequence(output, batch_first=self.batch_first)\n",
    "            else:\n",
    "                if self.batch_first:\n",
    "                    seq_lengths = output.size(0) * [output.size(1)]\n",
    "                else:\n",
    "                    seq_lengths = output.size(1) * [output.size(0)]\n",
    "\n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1)\n",
    "\n",
    "            output, seq_lengths = washout_tensor(output, washout, seq_lengths)\n",
    "\n",
    "            if self.w_io:\n",
    "                if is_packed:\n",
    "                    input, input_lengths = pad_packed_sequence(input,\n",
    "                                                          batch_first=self.batch_first)\n",
    "                else:\n",
    "                    input_lengths = [input.size(0)] * input.size(1)\n",
    "\n",
    "                if self.batch_first:\n",
    "                    input = input.transpose(0, 1)\n",
    "\n",
    "                input, _ = washout_tensor(input, washout, input_lengths)\n",
    "                output = torch.cat([input, output], -1)\n",
    "\n",
    "            if self.readout_training == 'gd' or target is None:\n",
    "                with torch.enable_grad():\n",
    "                    output = self.readout(output)\n",
    "\n",
    "                    if is_packed:\n",
    "                        for i in range(output.size(1)):\n",
    "                            if seq_lengths[i] < output.size(0):\n",
    "                                output[seq_lengths[i]:, i] = 0\n",
    "\n",
    "                    if self.batch_first:\n",
    "                        output = output.transpose(0, 1)\n",
    "\n",
    "                    # Uncomment if you want packed output.\n",
    "                    if is_packed:\n",
    "                        output = pack_padded_sequence(output, seq_lengths,\n",
    "                                                      batch_first=self.batch_first)\n",
    "                    # print(output.shape)\n",
    "                    output = self.dense_time(output.squeeze(-1).permute(1,0))\n",
    "\n",
    "                    # output = self.dense_time(output.permute(1,2,0)).squeeze(-1)\n",
    "                    return output\n",
    "\n",
    "            else:\n",
    "                batch_size = output.size(1)\n",
    "\n",
    "                X = torch.ones(target.size(0), 1 + output.size(2), device=target.device)\n",
    "                row = 0\n",
    "                for s in range(batch_size):\n",
    "                    if self.output_steps == 'all':\n",
    "                        X[row:row + seq_lengths[s], 1:] = output[:seq_lengths[s],\n",
    "                                                          s]\n",
    "                        row += seq_lengths[s]\n",
    "                    elif self.output_steps == 'mean':\n",
    "                        X[row, 1:] = torch.mean(output[:seq_lengths[s], s], 0)\n",
    "                        row += 1\n",
    "                    elif self.output_steps == 'last':\n",
    "                        X[row, 1:] = output[seq_lengths[s] - 1, s]\n",
    "                        row += 1\n",
    "\n",
    "                if self.readout_training == 'cholesky':\n",
    "                    if self.XTX is None:\n",
    "                        self.XTX = torch.mm(X.t(), X)\n",
    "                        self.XTy = torch.mm(X.t(), target)\n",
    "                    else:\n",
    "                        self.XTX += torch.mm(X.t(), X)\n",
    "                        self.XTy += torch.mm(X.t(), target)\n",
    "\n",
    "                elif self.readout_training == 'svd':\n",
    "                    # Scikit-Learn SVD solver for ridge regression.\n",
    "                    U, s, V = torch.svd(X)\n",
    "                    idx = s > 1e-15  # same default value as scipy.linalg.pinv\n",
    "                    s_nnz = s[idx][:, None]\n",
    "                    UTy = torch.mm(U.t(), target)\n",
    "                    d = torch.zeros(s.size(0), 1, device=X.device)\n",
    "                    d[idx] = s_nnz / (s_nnz ** 2 + self.lambda_reg)\n",
    "                    d_UT_y = d * UTy\n",
    "                    W = torch.mm(V, d_UT_y).t()\n",
    "\n",
    "                    self.readout.bias = nn.Parameter(W[:, 0])\n",
    "                    self.readout.weight = nn.Parameter(W[:, 1:])\n",
    "                elif self.readout_training == 'inv':\n",
    "                    self.X = X\n",
    "                    if self.XTX is None:\n",
    "                        self.XTX = torch.mm(X.t(), X)\n",
    "                        self.XTy = torch.mm(X.t(), target)\n",
    "                    else:\n",
    "                        self.XTX += torch.mm(X.t(), X)\n",
    "                        self.XTy += torch.mm(X.t(), target)\n",
    "                return None\n",
    "\n",
    "    def fit(self):\n",
    "        if self.readout_training in {'gd', 'svd'}:\n",
    "            return\n",
    "\n",
    "        if self.readout_training == 'cholesky':\n",
    "            W = torch.linalg.solve(self.XTy,\n",
    "                                   self.XTX + self.lambda_reg * torch.eye(\n",
    "                                       self.XTX.size(0), device=self.XTX.device))[0].t()\n",
    "            self.XTX = None\n",
    "            self.XTy = None\n",
    "\n",
    "            self.readout.bias = nn.Parameter(W[:, 0])\n",
    "            self.readout.weight = nn.Parameter(W[:, 1:])\n",
    "        elif self.readout_training == 'inv':\n",
    "            I = (self.lambda_reg * torch.eye(self.XTX.size(0))).to(\n",
    "                self.XTX.device)\n",
    "            A = self.XTX + I\n",
    "            X_rank = torch.linalg.matrix_rank(A).item()\n",
    "\n",
    "            if X_rank == self.X.size(0):\n",
    "                W = torch.mm(torch.inverse(A), self.XTy).t()\n",
    "            else:\n",
    "                W = torch.mm(torch.pinverse(A), self.XTy).t()\n",
    "\n",
    "            self.readout.bias = nn.Parameter(W[:, 0])\n",
    "            self.readout.weight = nn.Parameter(W[:, 1:])\n",
    "\n",
    "            self.XTX = None\n",
    "            self.XTy = None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.reservoir.reset_parameters()\n",
    "        self.readout.reset_parameters()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     x = torch.randn((128,32,15))\n",
    "#     washout_list = [int(0.2 * x.size(1))] * x.size(0)\n",
    "\n",
    "#     model = ESN(input_size=15,hidden_size=30,output_size=1,num_layers=3,pred_len=1)\n",
    "#     out = model(x)\n",
    "#     model.fit()\n",
    "#     print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-08T06:10:26.265447Z",
     "iopub.status.busy": "2025-12-08T06:10:26.265126Z",
     "iopub.status.idle": "2025-12-08T06:11:59.309082Z",
     "shell.execute_reply": "2025-12-08T06:11:59.307753Z",
     "shell.execute_reply.started": "2025-12-08T06:10:26.265423Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ESN\n",
      "----------train--------\n",
      "train X shape:torch.Size([2550, 32, 15])\n",
      "train y shape:torch.Size([2550, 1])\n",
      "----------val--------\n",
      "val X shape:torch.Size([450, 32, 15])\n",
      "val y shape:torch.Size([450, 1])\n",
      "----------test--------\n",
      "test X shape:torch.Size([936, 32, 15])\n",
      "test y shape:torch.Size([936, 1])\n",
      "| end of epoch   1 | time:  0.56s  | train loss 0.1537946478| test loss 0.1413835260 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.57s  | train loss 0.0798582253| test loss 0.0704294167 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.54s  | train loss 0.0357993318| test loss 0.0309067947 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.54s  | train loss 0.0201718994| test loss 0.0205095397 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.53s  | train loss 0.0165046506| test loss 0.0191757981 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  0.55s  | train loss 0.0149024633| test loss 0.0184159637 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  0.53s  | train loss 0.0168794130| test loss 0.0206896763 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  0.55s  | train loss 0.0133608367| test loss 0.0157248706 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  0.53s  | train loss 0.0154720112| test loss 0.0180468682 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  0.53s  | train loss 0.0126124959| test loss 0.0155239005 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  0.55s  | train loss 0.0110840153| test loss 0.0134791256 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  0.55s  | train loss 0.0121399709| test loss 0.0144087317 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  0.53s  | train loss 0.0110860862| test loss 0.0135729505 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  0.55s  | train loss 0.0092576937| test loss 0.0117025646 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  0.54s  | train loss 0.0111059411| test loss 0.0128294983 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  0.54s  | train loss 0.0086169592| test loss 0.0103309847 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  0.59s  | train loss 0.0083231135| test loss 0.0095317012 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  0.53s  | train loss 0.0081649847| test loss 0.0096663564 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  0.57s  | train loss 0.0084812335| test loss 0.0095795868 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  0.53s  | train loss 0.0076295559| test loss 0.0086751027 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  0.60s  | train loss 0.0073067980| test loss 0.0083209023 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  0.56s  | train loss 0.0074501299| test loss 0.0090066756 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  0.54s  | train loss 0.0071271611| test loss 0.0076740360 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  0.53s  | train loss 0.0066430792| test loss 0.0079058687 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  0.58s  | train loss 0.0076516870| test loss 0.0077383272 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  0.55s  | train loss 0.0085937096| test loss 0.0087439153 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  0.53s  | train loss 0.0067456265| test loss 0.0069740109 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  0.60s  | train loss 0.0074412611| test loss 0.0075595754 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  0.53s  | train loss 0.0063543322| test loss 0.0066837403 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  0.59s  | train loss 0.0065409506| test loss 0.0065604919 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  0.54s  | train loss 0.0062889801| test loss 0.0070511435 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  0.54s  | train loss 0.0066310047| test loss 0.0074166072 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  0.53s  | train loss 0.0059824775| test loss 0.0065241394 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  0.53s  | train loss 0.0059666758| test loss 0.0060635536 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  0.54s  | train loss 0.0058212965| test loss 0.0062442513 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  0.54s  | train loss 0.0085619732| test loss 0.0079798384 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  0.58s  | train loss 0.0064244602| test loss 0.0064690627 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  0.54s  | train loss 0.0056496992| test loss 0.0057739734 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  0.60s  | train loss 0.0067115992| test loss 0.0062182176 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  0.54s  | train loss 0.0055652708| test loss 0.0055493143 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  0.54s  | train loss 0.0055474154| test loss 0.0053876885 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  0.54s  | train loss 0.0054884221| test loss 0.0051527118 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  0.53s  | train loss 0.0069618707| test loss 0.0073135851 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  0.57s  | train loss 0.0053321652| test loss 0.0058286668 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  0.54s  | train loss 0.0062800204| test loss 0.0063836779 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  0.56s  | train loss 0.0052146811| test loss 0.0051891333 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  0.54s  | train loss 0.0051715130| test loss 0.0052932639 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  0.60s  | train loss 0.0051684366| test loss 0.0055165367 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  0.55s  | train loss 0.0060935781| test loss 0.0067997407 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  0.54s  | train loss 0.0049371644| test loss 0.0053564477 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  0.56s  | train loss 0.0051669391| test loss 0.0048643035 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  0.55s  | train loss 0.0054533432| test loss 0.0058235380 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  0.55s  | train loss 0.0071554684| test loss 0.0075855625 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  0.57s  | train loss 0.0052645355| test loss 0.0054144595 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  0.61s  | train loss 0.0052563614| test loss 0.0050437877 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  0.53s  | train loss 0.0055654662| test loss 0.0053614764 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  0.57s  | train loss 0.0047602069| test loss 0.0048005627 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  0.55s  | train loss 0.0048296190| test loss 0.0046452800 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  0.54s  | train loss 0.0047659288| test loss 0.0051334845 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time:  0.55s  | train loss 0.0046901924| test loss 0.0050635025 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  0.54s  | train loss 0.0047429616| test loss 0.0051352890 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  0.56s  | train loss 0.0060250338| test loss 0.0057845992 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  0.54s  | train loss 0.0045553634| test loss 0.0044197423 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  0.58s  | train loss 0.0054619577| test loss 0.0059868118 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  0.55s  | train loss 0.0049361889| test loss 0.0056164311 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  0.54s  | train loss 0.0047185774| test loss 0.0044472761 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  0.53s  | train loss 0.0044058176| test loss 0.0047152962 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  0.54s  | train loss 0.0044022414| test loss 0.0043609557 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  0.54s  | train loss 0.0056967338| test loss 0.0060559277 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time:  0.54s  | train loss 0.0058309123| test loss 0.0058543661 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  0.53s  | train loss 0.0044917887| test loss 0.0048095576 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  0.55s  | train loss 0.0045779229| test loss 0.0042011631 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  0.63s  | train loss 0.0048636100| test loss 0.0052490829 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  0.54s  | train loss 0.0043104543| test loss 0.0043753799 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  0.57s  | train loss 0.0041943913| test loss 0.0044958272 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  0.54s  | train loss 0.0045303083| test loss 0.0048663712 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  0.54s  | train loss 0.0042481461| test loss 0.0042820868 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  0.54s  | train loss 0.0042443621| test loss 0.0040894695 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  0.55s  | train loss 0.0040958586| test loss 0.0045471950 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time:  0.55s  | train loss 0.0039576140| test loss 0.0045428074 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  0.55s  | train loss 0.0040076367| test loss 0.0044154526 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  0.56s  | train loss 0.0040735301| test loss 0.0048549502 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  0.54s  | train loss 0.0057444456| test loss 0.0060684325 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  0.55s  | train loss 0.0047671085| test loss 0.0053186844 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  0.54s  | train loss 0.0047628886| test loss 0.0050500811 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  0.54s  | train loss 0.0043413245| test loss 0.0050933354 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  0.53s  | train loss 0.0044477986| test loss 0.0046322170 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  0.58s  | train loss 0.0042041962| test loss 0.0046117618 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  0.56s  | train loss 0.0040838876| test loss 0.0042712164 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time:  0.54s  | train loss 0.0046630163| test loss 0.0053143828 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  0.59s  | train loss 0.0042231780| test loss 0.0050498054 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  0.57s  | train loss 0.0048880532| test loss 0.0054105186 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  0.63s  | train loss 0.0040803094| test loss 0.0043094118 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  0.57s  | train loss 0.0038727511| test loss 0.0042032097 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  0.59s  | train loss 0.0041298723| test loss 0.0043960184 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  0.60s  | train loss 0.0053550772| test loss 0.0058335345 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  0.56s  | train loss 0.0042521117| test loss 0.0043468011 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  0.54s  | train loss 0.0039123898| test loss 0.0041148351 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  0.54s  | train loss 0.0043254497| test loss 0.0042086302 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  0.53s  | train loss 0.0036465600| test loss 0.0042452456 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 101 | time:  0.58s  | train loss 0.0037160715| test loss 0.0039971503 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 102 | time:  0.57s  | train loss 0.0035692654| test loss 0.0042239451 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 103 | time:  0.63s  | train loss 0.0038982827| test loss 0.0043218103 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 104 | time:  0.53s  | train loss 0.0044801752| test loss 0.0050112363 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 105 | time:  0.55s  | train loss 0.0035806559| test loss 0.0041201299 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 106 | time:  0.56s  | train loss 0.0039968307| test loss 0.0045738308 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 107 | time:  0.54s  | train loss 0.0039455573| test loss 0.0044012740 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 108 | time:  0.54s  | train loss 0.0036569573| test loss 0.0042148183 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 109 | time:  0.61s  | train loss 0.0034444200| test loss 0.0038931474 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 110 | time:  0.54s  | train loss 0.0036562017| test loss 0.0039617775 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 111 | time:  0.63s  | train loss 0.0034315252| test loss 0.0038099454 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 112 | time:  0.58s  | train loss 0.0051556320| test loss 0.0057627364 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 113 | time:  0.54s  | train loss 0.0035217270| test loss 0.0041100702 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 114 | time:  0.55s  | train loss 0.0033194386| test loss 0.0038254599 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 115 | time:  0.54s  | train loss 0.0040114608| test loss 0.0045121013 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 116 | time:  0.57s  | train loss 0.0035399415| test loss 0.0038965421 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 117 | time:  0.53s  | train loss 0.0035714486| test loss 0.0039981077 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 118 | time:  0.53s  | train loss 0.0032898436| test loss 0.0037958732 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 119 | time:  0.54s  | train loss 0.0033044035| test loss 0.0037510624 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 120 | time:  0.54s  | train loss 0.0034307817| test loss 0.0036298543 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 121 | time:  0.56s  | train loss 0.0032706976| test loss 0.0035771895 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 122 | time:  0.53s  | train loss 0.0032038564| test loss 0.0037579875 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 123 | time:  0.54s  | train loss 0.0032366436| test loss 0.0036780556 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 124 | time:  0.55s  | train loss 0.0040069001| test loss 0.0045109604 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 125 | time:  0.54s  | train loss 0.0032184502| test loss 0.0036751740 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 126 | time:  0.54s  | train loss 0.0035547186| test loss 0.0036863757 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 127 | time:  0.57s  | train loss 0.0030680505| test loss 0.0038007575 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 128 | time:  0.54s  | train loss 0.0031301900| test loss 0.0035663854 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 129 | time:  0.54s  | train loss 0.0036497757| test loss 0.0041559170 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 130 | time:  0.54s  | train loss 0.0030944223| test loss 0.0038285865 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 131 | time:  0.54s  | train loss 0.0030229364| test loss 0.0038369705 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 132 | time:  0.57s  | train loss 0.0035460213| test loss 0.0041181326 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 133 | time:  0.54s  | train loss 0.0032304922| test loss 0.0040482024 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 134 | time:  0.55s  | train loss 0.0029769355| test loss 0.0037218438 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 135 | time:  0.53s  | train loss 0.0029960269| test loss 0.0034995343 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 136 | time:  0.54s  | train loss 0.0032137792| test loss 0.0043260476 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 137 | time:  0.53s  | train loss 0.0033644946| test loss 0.0042629922 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 138 | time:  0.56s  | train loss 0.0029846746| test loss 0.0035394419 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 139 | time:  0.54s  | train loss 0.0030219494| test loss 0.0035012631 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 140 | time:  0.59s  | train loss 0.0029334091| test loss 0.0034894620 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 141 | time:  0.54s  | train loss 0.0052780304| test loss 0.0057804697 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 142 | time:  0.58s  | train loss 0.0029261257| test loss 0.0033363081 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 143 | time:  0.54s  | train loss 0.0030315926| test loss 0.0032698571 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 144 | time:  0.53s  | train loss 0.0033092603| test loss 0.0032728667 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 145 | time:  0.58s  | train loss 0.0033958558| test loss 0.0041051205 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 146 | time:  0.59s  | train loss 0.0037018051| test loss 0.0042429768 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 147 | time:  0.53s  | train loss 0.0028868273| test loss 0.0035057253 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 148 | time:  0.53s  | train loss 0.0029040794| test loss 0.0032685263 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 149 | time:  0.59s  | train loss 0.0037135988| test loss 0.0043047133 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time:  0.55s  | train loss 0.0028396642| test loss 0.0036409356 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 151 | time:  0.60s  | train loss 0.0029405004| test loss 0.0037110805 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 152 | time:  0.53s  | train loss 0.0035108422| test loss 0.0042620882 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 153 | time:  0.54s  | train loss 0.0035679297| test loss 0.0043985347 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 154 | time:  0.56s  | train loss 0.0028143504| test loss 0.0031758507 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 155 | time:  0.54s  | train loss 0.0027559311| test loss 0.0035257508 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 156 | time:  0.55s  | train loss 0.0028400844| test loss 0.0033198130 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 157 | time:  0.55s  | train loss 0.0027025120| test loss 0.0034647097 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 158 | time:  0.53s  | train loss 0.0028867384| test loss 0.0033135325 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 159 | time:  0.53s  | train loss 0.0027136054| test loss 0.0031967991 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 160 | time:  0.59s  | train loss 0.0026439025| test loss 0.0035904992 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 161 | time:  0.55s  | train loss 0.0029838944| test loss 0.0032359449 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 162 | time:  0.55s  | train loss 0.0033272668| test loss 0.0044000347 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 163 | time:  0.54s  | train loss 0.0028353472| test loss 0.0035481389 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 164 | time:  0.56s  | train loss 0.0027423922| test loss 0.0035433614 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 165 | time:  0.54s  | train loss 0.0025701485| test loss 0.0032412403 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 166 | time:  0.54s  | train loss 0.0034317034| test loss 0.0039223962 \n",
      "------------------------------------------------------------------------------------------\n",
      "| end of epoch 167 | time:  0.56s  | train loss 0.0026304850| test loss 0.0034009241 \n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 422\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, model_name)\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# model_name = 'LSTM'\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[43mread_npy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlorenz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# read_npy('power',model_name,epochs = 300,load_name='sr', weight_decay=0.5,lr = 0.001,seed=i)\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# read_npy('power',model_name,epochs = 300,load_name='tr', weight_decay=0.5,lr = 0.001,seed=i)\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# read_npy('power',model_name,epochs = 300,load_name='sr', weight_decay=0.5,lr = 0.001,seed=i)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 314\u001b[0m, in \u001b[0;36mread_npy\u001b[0;34m(type_name, model_name, epochs, load_name, weight_decay, lr, seed, pred_len, time_len)\u001b[0m\n\u001b[1;32m    311\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    312\u001b[0m train_model \u001b[38;5;241m=\u001b[39m train(model, optimizer, scheduler, epoch,train_dataloader, train_seq,type_loss)\n\u001b[0;32m--> 314\u001b[0m train_loss, train_output, train_target \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtype_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m test_loss, test_output, test_target \u001b[38;5;241m=\u001b[39m evaluate(train_model, test_dataloader, test_seq,type_loss)\n\u001b[1;32m    316\u001b[0m list_train_loss\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[24], line 86\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(eval_model, dataloader, data_source_x, type_loss)\u001b[0m\n\u001b[1;32m     84\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     85\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 86\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     88\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, targets)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 158\u001b[0m, in \u001b[0;36mESN.forward\u001b[0;34m(self, input, h_0, target)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first:\n\u001b[1;32m    156\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m output, seq_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mwashout_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwashout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_io:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_packed:\n",
      "Cell \u001b[0;32mIn[23], line 54\u001b[0m, in \u001b[0;36mwashout_tensor\u001b[0;34m(tensor, washout, seq_lengths, bidirectional, batch_first)\u001b[0m\n\u001b[1;32m     51\u001b[0m tensor[seq_lengths[b] \u001b[38;5;241m-\u001b[39m washout[b]:, b] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     52\u001b[0m seq_lengths[b] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m washout[b]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bidirectional:\n\u001b[1;32m     55\u001b[0m     tensor[seq_lengths[b] \u001b[38;5;241m-\u001b[39m washout[b]:, b] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     56\u001b[0m     seq_lengths[b] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m washout[b]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "\n",
    "# 环境设置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # 使用gpu\n",
    "batch_size = 128\n",
    "criterion = nn.MSELoss()\n",
    "start_time = time.time()\n",
    "\n",
    "# 能固定dataloader的结果，使复现结果一致\n",
    "def setup_seed(seed):\n",
    "   torch.manual_seed(seed)\n",
    "   torch.cuda.manual_seed_all(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "   torch.backends.cudnn.deterministic = True\n",
    "# setup_seed(20)\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "  # 确保输入数据长度一致\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"长度不一致：y_true 和 y_pred\")\n",
    "\n",
    "      # 计算MSE\n",
    "    squared_errors = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
    "    return sum(squared_errors) / len(y_true)\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, epoch, train_dataloader, train_seq, type_loss):\n",
    "    model.train()  # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for batch_index,batch_data in enumerate(train_dataloader):\n",
    "        data,targets = batch_data       # torch.Size([B, L, D]) torch.Size([B, pred_len])\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        if type_loss == 'mse':\n",
    "            loss = criterion(output, targets)\n",
    "        else:\n",
    "            loss, loss_shape, loss_temporal = dilate_loss(output, targets, alpha=0.8, gamma=0.01, device=device)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # 防止梯度爆炸或梯度消失问题\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_seq) / batch_size/5 )\n",
    "        if batch_index % log_interval == 0 and batch_index > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            # print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "            #       'lr {:02.6f} | {:5.2f} ms | '\n",
    "            #       'loss {:5.5f}'.format(\n",
    "            #     epoch, batch_index, len(train_seq) // batch_size, scheduler.get_lr()[0],\n",
    "            #                   elapsed * 1000 / log_interval,cur_loss))  # , math.exp(cur_loss)\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(eval_model, dataloader, data_source_x,type_loss):\n",
    "    eval_model.eval()  # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    result = torch.Tensor(0).to(device)\n",
    "    truth = torch.Tensor(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for batch_index,dataset in enumerate(dataloader):\n",
    "            data, targets = dataset\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = eval_model(data)\n",
    "            if type_loss == 'mse':\n",
    "                loss = criterion(output, targets)\n",
    "                total_loss +=  len(data)*loss.item()\n",
    "            else:\n",
    "                loss, loss_shape, loss_temporal = dilate_loss(output, targets, alpha=0.8, gamma=0.01, device=device)\n",
    "                total_loss +=  len(data)*loss.item()\n",
    "            result = torch.cat((result.cpu(), output.cpu()),0)  # todo: check this. -> looks good to me\n",
    "            truth = torch.cat((truth.cpu(), targets.cpu()), 0)\n",
    "    return total_loss / len(data_source_x),result,truth\n",
    "\n",
    "\n",
    "def get_model(type_name, model_name, load_name, pred_len=1,time_len=32):\n",
    "    model = None        # 定义模型\n",
    "\n",
    "    if load_name == 'sr':\n",
    "        if model_name == 'LSTM':\n",
    "            if type_name == 'lorenz':\n",
    "                # model = LSTM_Model(seq_len=32, input_dim=15, hidden_dim1=128, hidden_dim2=32, pred_len=pred_len)\n",
    "                model = LSTM_Model(seq_len=30, input_dim=15, hidden_dim1=128, hidden_dim2=32, pred_len=pred_len,num_experts=4,k=2)\n",
    "\n",
    "            if type_name == 'power':\n",
    "                # model = LSTM_Model(seq_len=32, input_dim=30, hidden_dim1=128, hidden_dim2=64, pred_len=pred_len)\n",
    "                model = LSTM_Model(seq_len=30, input_dim=30, hidden_dim1=128, hidden_dim2=64, pred_len=pred_len,num_experts=8,k=2)\n",
    "\n",
    "        if model_name == 'Transformer':\n",
    "            if type_name == 'lorenz':\n",
    "                model = Transformer_Model(seq_len=30, pred_len=pred_len, enc_in=15,num_experts=4,k=2)\n",
    "            if type_name == 'power':\n",
    "                model = Transformer_Model(seq_len=30, pred_len=pred_len, enc_in=30,num_experts=8,k=2)\n",
    "                \n",
    "        if model_name == 'DLinear':\n",
    "            if type_name == 'lorenz':\n",
    "                model = DLinear_Model(seq_len=30,pred_len=pred_len,enc_in=15,individual=False,num_experts=4,k=2)\n",
    "            if type_name == 'power':\n",
    "                model = DLinear_Model(seq_len=30,pred_len=pred_len,enc_in=30,individual=False,num_experts=8,k=2)\n",
    "\n",
    "        if model_name == 'TCN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = TCN_Model(num_inputs=15, num_channels=[10,5], kernel_size=2,seq_len=30,pred_len=pred_len,num_experts=3,k=2)\n",
    "            if type_name == 'power':\n",
    "                model = TCN_Model(num_inputs=30, num_channels=[10,5], kernel_size=2,seq_len=30,pred_len=pred_len,num_experts=8,k=2)\n",
    "\n",
    "        if model_name == 'ModernTCN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = ModernTCN(M=15,L=30,T=pred_len,D=64,num_experts=3,k=2)\n",
    "            if type_name == 'power':\n",
    "                model = ModernTCN(M=30,L=32,T=pred_len,D=32,num_experts=8,k=2)\n",
    "        \n",
    "        if model_name == 'Att_CNN_LSTM':\n",
    "            if type_name == 'lorenz':\n",
    "                model = Att_CNN_LSTM(in_channels=15,out_channels=16,hidden_size=128,seq_len=30,kernel_size=2,dilation_size=1,pred_len=pred_len,num_experts=3,k=2)\n",
    "            if type_name == 'power':\n",
    "                model = Att_CNN_LSTM(in_channels=30,out_channels=16,hidden_size=128,seq_len=30,kernel_size=2,dilation_size=1,pred_len=pred_len,num_experts=8,k=2)\n",
    "        \n",
    "        if model_name == 'ESN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = ESN(input_size=15, hidden_size=200,time_len=30, output_size=1,pred_len=pred_len, num_layers=1,num_experts=2,k=2)\n",
    "            if type_name == 'power':\n",
    "                model = ESN(input_size=30, hidden_size=200, time_len=30,output_size=1,pred_len=pred_len, num_layers=1,num_experts=4,k=2)\n",
    "\n",
    "    else:\n",
    "        if model_name == 'LSTM':\n",
    "            if type_name == 'lorenz':\n",
    "                model = LSTM_Model(seq_len=time_len, input_dim=15, hidden_dim1=128, hidden_dim2=64, pred_len=pred_len)\n",
    "            if type_name == 'rossler':\n",
    "                model = LSTM_Model(seq_len=time_len, input_dim=13, hidden_dim1=128, hidden_dim2=64, pred_len=pred_len)\n",
    "            if type_name == 'power':\n",
    "                model = LSTM_Model(seq_len=time_len, input_dim=30, hidden_dim1=128, hidden_dim2=64, pred_len=pred_len)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = LSTM_Model(seq_len=time_len, input_dim=40, hidden_dim1=128, hidden_dim2=64, pred_len=pred_len)\n",
    "            if type_name == 'KS':\n",
    "                model = LSTM_Model(seq_len=time_len, input_dim=80, hidden_dim1=64, hidden_dim2=32, pred_len=pred_len)\n",
    "\n",
    "        \n",
    "        if model_name == 'Transformer':\n",
    "            if type_name == 'lorenz':\n",
    "                model = Transformer_Model(seq_len=time_len, pred_len=pred_len, enc_in=15)\n",
    "            if type_name == 'rossler':\n",
    "                model = Transformer_Model(seq_len=time_len, pred_len=pred_len, enc_in=13)\n",
    "            if type_name == 'power':\n",
    "                model = Transformer_Model(seq_len=time_len, pred_len=pred_len, enc_in=30)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = Transformer_Model(seq_len=time_len, pred_len=pred_len, enc_in=40)\n",
    "            if type_name == 'KS':\n",
    "                model = Transformer_Model(seq_len=time_len, pred_len=pred_len, enc_in=80)\n",
    "\n",
    "        \n",
    "        if model_name == 'DLinear':\n",
    "            if type_name == 'lorenz':\n",
    "                model = DLinear_Model(seq_len=time_len,pred_len=pred_len,enc_in=15,individual=False)\n",
    "            if type_name == 'rossler':\n",
    "                model = DLinear_Model(seq_len=time_len,pred_len=pred_len,enc_in=13,individual=False)\n",
    "            if type_name == 'power':\n",
    "                model = DLinear_Model(seq_len=time_len,pred_len=pred_len,enc_in=30,individual=False)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = DLinear_Model(seq_len=time_len,pred_len=pred_len,enc_in=40,individual=False)\n",
    "            if type_name == 'KS':\n",
    "                model = DLinear_Model(seq_len=time_len,pred_len=pred_len,enc_in=80,individual=False)                \n",
    "                \n",
    "        if model_name == 'TCN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = TCN_Model(num_inputs=15, num_channels=[10,5], kernel_size=2,seq_len=time_len,pred_len=pred_len)\n",
    "            if type_name == 'rossler':\n",
    "                model = TCN_Model(num_inputs=13, num_channels=[10,5], kernel_size=2,seq_len=time_len,pred_len=pred_len)            \n",
    "            if type_name == 'power':\n",
    "                model = TCN_Model(num_inputs=30, num_channels=[10,5], kernel_size=2,seq_len=time_len,pred_len=pred_len)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = TCN_Model(num_inputs=40, num_channels=[10,5], kernel_size=2,seq_len=time_len,pred_len=pred_len)\n",
    "            if type_name == 'KS':\n",
    "                model = TCN_Model(num_inputs=80, num_channels=[10,5], kernel_size=2,seq_len=time_len,pred_len=pred_len)\n",
    "\n",
    "        \n",
    "        if model_name == 'ModernTCN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = ModernTCN(M=15,L=time_len,T=pred_len,D=64)\n",
    "            if type_name == 'rossler':\n",
    "                model = ModernTCN(M=13,L=time_len,T=pred_len,D=64)            \n",
    "            if type_name == 'power':\n",
    "                model = ModernTCN(M=30,L=time_len,T=pred_len,D=64)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = ModernTCN(M=40,L=time_len,T=pred_len,D=64)\n",
    "            if type_name == 'KS':\n",
    "                model = ModernTCN(M=80,L=time_len,T=pred_len,D=64)\n",
    "\n",
    "                \n",
    "        if model_name == 'Att_CNN_LSTM':\n",
    "            if type_name == 'lorenz':\n",
    "                model = Att_CNN_LSTM(in_channels=15,out_channels=16,hidden_size=128,seq_len=time_len,kernel_size=2,dilation_size=1,pred_len=pred_len)\n",
    "            if type_name == 'rossler':\n",
    "                model = Att_CNN_LSTM(in_channels=13,out_channels=16,hidden_size=128,seq_len=time_len,kernel_size=2,dilation_size=1,pred_len=pred_len)\n",
    "            if type_name == 'power':\n",
    "                model = Att_CNN_LSTM(in_channels=30,out_channels=16,hidden_size=128,seq_len=time_len,kernel_size=2,dilation_size=1,pred_len=pred_len)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = Att_CNN_LSTM(in_channels=40,out_channels=16,hidden_size=128,seq_len=time_len,kernel_size=2,dilation_size=1,pred_len=pred_len)\n",
    "            if type_name == 'KS':\n",
    "                model = Att_CNN_LSTM(in_channels=80,out_channels=32,hidden_size=256,seq_len=time_len,kernel_size=2,dilation_size=1,pred_len=pred_len)\n",
    "\n",
    "                \n",
    "        if model_name == 'ESN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = ESN(input_size=15, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "            if type_name == 'rossler':\n",
    "                model = ESN(input_size=13, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "            if type_name == 'power':\n",
    "                model = ESN(input_size=30, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "            if type_name == 'lorenz-96':\n",
    "                model = ESN(input_size=40, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "            if type_name == 'KS':\n",
    "                model = ESN(input_size=80, hidden_size=200, output_size=80, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "                \n",
    "        if model_name == 'WESN':\n",
    "            if type_name == 'lorenz':\n",
    "                model = ESN(input_size=18, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "            if type_name == 'rossler':\n",
    "                model = ESN(input_size=18, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "            if type_name == 'power':\n",
    "                model = ESN(input_size=36, hidden_size=300, output_size=1, num_layers=1,pred_len=pred_len,time_len=time_len)\n",
    "                \n",
    "    return model\n",
    "\n",
    "\n",
    "def read_npy(type_name,model_name,epochs,load_name,weight_decay,lr = 0.001,seed=0,pred_len=1,time_len=32):\n",
    "    if pred_len == 1:\n",
    "        if model_name == 'WESN':\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_Wave_{}_{}.npy'.format(type_name,seed),allow_pickle=True).item()\n",
    "        else:\n",
    "            if load_name == 'sr':\n",
    "                saved_dict = np.load(r'/kaggle/input/original-chaotic-data/sr_{}_{}.npy'.format(type_name,seed),allow_pickle=True).item()\n",
    "            else:\n",
    "                saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_{}_{}.npy'.format(type_name,seed),allow_pickle=True).item()\n",
    "        # saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_KS_42.npy',allow_pickle=True).item()\n",
    "\n",
    "    else:\n",
    "        # if model_name == 'WESN':\n",
    "        #     saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_Wave_{}_42_({}).npy'.format(type_name,pred_len),allow_pickle=True).item()\n",
    "        # else:\n",
    "        #     print('looking here!')\n",
    "        #     # saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_{}_{}_({}).npy'.format(type_name,seed,pred_len),allow_pickle=True).item()\n",
    "        #     saved_dict = np.load(r'/kaggle/input/original-chaotic-data/sr_{}_({}_{}).npy'.format(type_name,time_len,pred_len),allow_pickle=True).item()\n",
    "       if model_name == 'WESN':\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/tr_Wave_{}_({}_{}).npy'.format(type_name,time_len,pred_len),allow_pickle=True).item()\n",
    "       else:\n",
    "            saved_dict = np.load(r'/kaggle/input/original-chaotic-data/sr_{}_({}_{}).npy'.format(type_name,time_len,pred_len),allow_pickle=True).item()\n",
    "\n",
    "    \n",
    "    \n",
    "    train_seq = saved_dict['train']['train_seq'].to(device)\n",
    "    train_label = saved_dict['train']['train_label'].to(device)\n",
    "    train_dataloader = saved_dict['train']['train_dataloader']\n",
    "\n",
    "    val_seq = saved_dict['val']['val_seq'].to(device)\n",
    "    val_label = saved_dict['val']['val_label'].to(device)\n",
    "    val_dataloader = saved_dict['val']['val_dataloader']\n",
    "\n",
    "    test_seq = saved_dict['test']['test_seq'].to(device)\n",
    "    test_label = saved_dict['test']['test_label'].to(device)\n",
    "    test_dataloader = saved_dict['test']['test_dataloader']\n",
    "\n",
    "    print('----------train--------')\n",
    "    print(f'train X shape:{train_seq.shape}')\n",
    "    print(f'train y shape:{train_label.shape}')\n",
    "\n",
    "    print('----------val--------')\n",
    "    print(f'val X shape:{val_seq.shape}')\n",
    "    print(f'val y shape:{val_label.shape}')\n",
    "\n",
    "    print('----------test--------')\n",
    "    print(f'test X shape:{test_seq.shape}')\n",
    "    print(f'test y shape:{test_label.shape}')\n",
    "\n",
    "    model = get_model(type_name, model_name, load_name,pred_len=pred_len,time_len=time_len).to(device)\n",
    "\n",
    "    type_loss = 'mse'\n",
    "    # type_loss = 'dilate'\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.98)       # 学习率调度器对象,调度器会在每个10个epoch后将学习率乘以gamma。\n",
    "    best_test_loss = 1000\n",
    "    best_val_output, best_val_target,best_test_output, best_test_target = 0, 0, 0, 0\n",
    "    best_model = None\n",
    "    list_train_loss, list_test_loss = [], []\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train_model = train(model, optimizer, scheduler, epoch,train_dataloader, train_seq,type_loss)\n",
    "\n",
    "        train_loss, train_output, train_target = evaluate(train_model, train_dataloader, train_seq,type_loss)\n",
    "        test_loss, test_output, test_target = evaluate(train_model, test_dataloader, test_seq,type_loss)\n",
    "        list_train_loss.append(train_loss)\n",
    "        list_test_loss.append(test_loss)\n",
    "\n",
    "        if test_loss<best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_test_output = test_output\n",
    "            best_test_target = test_target\n",
    "            best_model = train_model\n",
    "\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s  | train loss {:.10f}| test loss {:.10f} '.format(\n",
    "            epoch, (time.time() - epoch_start_time), train_loss, test_loss))\n",
    "        print('-' * 90)\n",
    "        \n",
    "        scheduler.step()        # 学习率调度器对象\n",
    "\n",
    "    data_out = pd.DataFrame({'true':[i[0] for i in best_test_target.tolist()],\n",
    "                             'pred':[i[0] for i in best_test_output.tolist()]},\n",
    "                            index=range(len(best_test_output)))\n",
    "    \n",
    "    print(data_out)\n",
    "    print(mean_squared_error(best_test_target,best_test_output))\n",
    "\n",
    "    # 指定CSV文件的保存路径和文件名\n",
    "    folder_path = '/kaggle/working/new1/'\n",
    "\n",
    "    \n",
    "    # 检查文件夹是否存在，如果不存在则创建\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    if type_name!='KS':\n",
    "        if pred_len == 1:\n",
    "            data_out = pd.DataFrame({'true':[i[0] for i in best_test_target.tolist()],\n",
    "                                     'pred':[i[0] for i in best_test_output.tolist()]},\n",
    "                                      index=range(len(best_test_output)))\n",
    "            file_name = 'MOE_{}_{}_{}_{}.csv'.format(load_name,type_name,model_name,seed)\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            data_out.to_csv(file_path)\n",
    "            \n",
    "        else:\n",
    "            columns = ['true{}'.format(i+1) for i in range(pred_len)]\n",
    "            columns.extend(['pred{}'.format(i+1) for i in range(pred_len)])\n",
    "            true_df = pd.DataFrame(best_test_target.numpy(), columns=columns[:pred_len])\n",
    "            pred_df = pd.DataFrame(best_test_output.numpy(), columns=columns[pred_len:])\n",
    "            data_out = pd.concat([true_df, pred_df], axis=1)\n",
    "            print(data_out)\n",
    "            \n",
    "            # get_all_result(true_df, pred_df)\n",
    "            # file_name = r'{}_{}_{}_{}_({}).csv'.format(load_name,type_name,model_name,seed,pred_len)\n",
    "            file_name = r'{}_{}_{}_({}_{}).csv'.format(load_name,type_name,model_name,time_len,pred_len)\n",
    "    \n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            data_out.to_csv(file_path)\n",
    "    else:\n",
    "        columns = ['true{}'.format(i+1) for i in range(80)]\n",
    "        columns.extend(['pred{}'.format(i+1) for i in range(80)])\n",
    "        true_df = pd.DataFrame(best_test_target.numpy(), columns=columns[:80])\n",
    "        pred_df = pd.DataFrame(best_test_output.numpy(), columns=columns[80:])\n",
    "        data_out = pd.concat([true_df, pred_df], axis=1)\n",
    "        print(data_out)\n",
    "        \n",
    "        # get_all_result(true_df, pred_df)\n",
    "        file_name = r'{}_{}_{}.csv'.format(load_name,type_name,model_name,time_len,pred_len)\n",
    "\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        data_out.to_csv(file_path)\n",
    "    \n",
    "\n",
    "    # plt.plot(best_test_target, label='真实值')\n",
    "    # plt.plot(best_test_output, label='预测值')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "# model_name = 'ESN'\n",
    "# read_npy('lorenz',model_name,epochs = 300,load_name='sr', weight_decay=0.02,lr = 0.001)\n",
    "# read_npy('power',model_name, epochs = 300,load_name='sr', weight_decay=0.02,lr = 0.001)\n",
    "\n",
    "\n",
    "# for time_len in [24,32,40,48,56,64]:\n",
    "# for time_len in [8,16]:\n",
    "#     for model_name in ['WESN']:\n",
    "#         read_npy('lorenz',model_name, epochs = 300, load_name='tr', weight_decay=0.02,lr = 0.001,seed=42,pred_len=6,time_len=time_len)\n",
    "#         read_npy('power',model_name, epochs = 300, load_name='tr', weight_decay=0.5,lr = 0.001,seed=42,pred_len=6,time_len=time_len)\n",
    "\n",
    "\n",
    "\n",
    "# for i in [2,3,4,5,6,7,8,9,10,11,12]:\n",
    "#     for model_name in ['ESN']:\n",
    "#         print(i)\n",
    "#         # read_npy('lorenz',model_name, epochs = 300, load_name='tr', weight_decay=0.02,lr = 0.001,seed=42,pred_len=i)\n",
    "#         # read_npy('rossler',model_name, epochs = 300, load_name='tr', weight_decay=0.02,lr = 0.001,seed=42,pred_len=i)\n",
    "#         read_npy('power',model_name, epochs = 300, load_name='tr', weight_decay=0.5,lr = 0.001,seed=42,pred_len=i)\n",
    "\n",
    "    \n",
    "    # model_name = 'Transformer'\n",
    "    # read_npy('power',model_name, epochs = 300, load_name='tr', weight_decay=0.5,lr = 0.001,seed=42,pred_len=i)\n",
    "\n",
    "    # model_name = 'DLinear'\n",
    "    # read_npy('power',model_name, epochs = 300, load_name='tr', weight_decay=0.5,lr = 0.001,seed=42,pred_len=i)\n",
    "\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    for model_name in ['ESN']:\n",
    "        print(i, model_name)\n",
    "        # model_name = 'LSTM'\n",
    "        read_npy('lorenz',model_name, epochs = 300, load_name='sr', weight_decay=0.02,lr = 0.001,seed=i)\n",
    "        # read_npy('power',model_name,epochs = 300,load_name='sr', weight_decay=0.5,lr = 0.001,seed=i)\n",
    "\n",
    "\n",
    "# for model_name in ['Att_CNN_LSTM']:\n",
    "#     read_npy('lorenz-96',model_name, epochs = 300, load_name='tr', weight_decay=0.9,lr = 0.001,seed=1,pred_len=1)\n",
    "\n",
    "\n",
    "#     read_npy('lorenz',model_name, epochs = 300, load_name='tr', weight_decay=0.02,lr = 0.001,seed=i)\n",
    "#     read_npy('lorenz',model_name, epochs = 300, load_name='sr', weight_decay=0.02,lr = 0.001,seed=i)\n",
    "\n",
    "    # read_npy('rossler',model_name, epochs = 300, load_name='tr', weight_decay=0.02,lr = 0.001,seed=i)\n",
    "\n",
    "    # read_npy('power',model_name,epochs = 300,load_name='tr', weight_decay=0.5,lr = 0.001,seed=i)\n",
    "    # read_npy('power',model_name,epochs = 300,load_name='sr', weight_decay=0.5,lr = 0.001,seed=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5442112,
     "sourceId": 13044261,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
